{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48178dc0",
   "metadata": {},
   "source": [
    "# AI Agents Development with Gemma\n",
    "\n",
    "This notebook is designed for the 5-Day AI Agents Intensive Course. It will be updated daily as we progress through the course.\n",
    "\n",
    "**Course Dates**: November 9-13, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367e5fe",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "**Important Note:** For the AI Agents course, the **primary platform is Kaggle Notebooks** where all dependencies are pre-configured. This local setup is optional for experimentation.\n",
    "\n",
    "### Platform Options:\n",
    "1. **Kaggle Notebooks** (Recommended) - All dependencies pre-installed\n",
    "2. **Google Colab** - Good for experimentation\n",
    "3. **Local Setup** - Requires Python 3.11 or earlier for tensorflow-text compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb3925a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Python 3.13.7\n",
      "\n",
      "‚ö†Ô∏è Note: tensorflow-text may not be available for Python 3.13 yet.\n",
      "   Options:\n",
      "   1. Use Kaggle notebooks (recommended for this course)\n",
      "   2. Create a Python 3.11 environment locally\n",
      "   3. Use Google Colab for local experimentation\n"
     ]
    }
   ],
   "source": [
    "# Check Python version for compatibility\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "\n",
    "# tensorflow-text compatibility note\n",
    "if sys.version_info >= (3, 13):\n",
    "    print(\"\\n‚ö†Ô∏è Note: tensorflow-text may not be available for Python 3.13 yet.\")\n",
    "    print(\"   Options:\")\n",
    "    print(\"   1. Use Kaggle notebooks (recommended for this course)\")\n",
    "    print(\"   2. Create a Python 3.11 environment locally\")\n",
    "    print(\"   3. Use Google Colab for local experimentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd63ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (for local experimentation only)\n",
    "# Note: The course codelabs should be completed on Kaggle platform\n",
    "# tensorflow-text requires Python <=3.12 currently\n",
    "\n",
    "%pip install -q -U google-generativeai python-dotenv\n",
    "\n",
    "# Uncomment below if using Python 3.11 or earlier:\n",
    "# %pip install -q -U tensorflow tensorflow-text keras-hub keras jax[cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dacb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete - 2025-11-09 19:49:00\n",
      "Keras backend: jax\n"
     ]
    }
   ],
   "source": [
    "# Basic imports for notebook\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    print(f\"‚úì Setup complete - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"‚úì google-generativeai loaded\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Run the installation cell above first\")\n",
    "\n",
    "# Optional: These are only needed if using Python 3.11 or earlier with local Gemma\n",
    "try:\n",
    "    import numpy as np\n",
    "    os.environ['KERAS_BACKEND'] = 'jax'\n",
    "    import keras\n",
    "    import keras_hub\n",
    "    print(f\"‚úì Keras backend: {keras.backend.backend()}\")\n",
    "    print(\"  (Optional - only needed for local Gemma experimentation)\")\n",
    "except ImportError:\n",
    "    print(\"‚ÑπÔ∏è  Keras/KerasHub not installed (not required for this course)\")\n",
    "    print(\"   Complete all codelabs on Kaggle where dependencies are pre-configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46166c",
   "metadata": {},
   "source": [
    "## API Configuration\n",
    "\n",
    "Configure Google AI Studio API for additional model access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea6bfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using local .env file\n",
      "‚úì Google AI API configured\n"
     ]
    }
   ],
   "source": [
    "# For Kaggle: Use Kaggle Secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    print(\"‚úì Using Kaggle Secrets\")\n",
    "except:\n",
    "    # For local: Use environment variables\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    print(\"‚úì Using local .env file\")\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    print(\"‚úì Google AI API configured\")\n",
    "else:\n",
    "    print(\"‚ö† Warning: API key not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f1360",
   "metadata": {},
   "source": [
    "## Gemma Model Setup\n",
    "\n",
    "**‚ö†Ô∏è Local Limitation:** Gemma via KerasHub requires `tensorflow-text`, which is not available for Python 3.13+ on Windows.\n",
    "\n",
    "### ‚úÖ Recommended Approach:\n",
    "- **Complete all course codelabs on [Kaggle](https://www.kaggle.com)** where Gemma works perfectly\n",
    "- **Use this notebook** for notes, documentation, and Gemini API experiments\n",
    "\n",
    "### üí° Alternative: Gemini API\n",
    "Below we'll use the Gemini API (which you have configured) to experiment with agent concepts locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gemma model (this may take a few minutes)...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<class 'keras_hub.src.models.gemma.gemma_tokenizer.GemmaTokenizer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras_hub.src.models.gemma.gemma_tokenizer', 'class_name': 'GemmaTokenizer', 'config': {'name': 'gemma_tokenizer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'int32'}, 'registered_name': None}, 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}, 'registered_name': 'keras_hub>GemmaTokenizer'}.\n\nException encountered: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}.\n\nException encountered: GemmaTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:317\u001b[39m, in \u001b[36mOperation.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\models\\gemma\\gemma_tokenizer.py:78\u001b[39m, in \u001b[36mGemmaTokenizer.__init__\u001b[39m\u001b[34m(self, proto, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m._add_special_token(\u001b[33m\"\u001b[39m\u001b[33m<pad>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpad_token\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\tokenizers\\sentence_piece_tokenizer.py:111\u001b[39m, in \u001b[36mSentencePieceTokenizer.__init__\u001b[39m\u001b[34m(self, proto, sequence_length, dtype, add_bos, add_eos, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOutput dtype must be an integer type or a string. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    108\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.proto = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\tokenizers\\tokenizer.py:70\u001b[39m, in \u001b[36mTokenizer.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m.config_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mconfig_file\u001b[39m\u001b[33m\"\u001b[39m, TOKENIZER_CONFIG_FILE)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mself\u001b[39m.file_assets = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\layers\\preprocessing\\preprocessing_layer.py:10\u001b[39m, in \u001b[36mPreprocessingLayer.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[43massert_tf_libs_installed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\tensor_utils.py:276\u001b[39m, in \u001b[36massert_tf_libs_installed\u001b[39m\u001b[34m(symbol_name)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tf_text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m tf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    277\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires `tensorflow` and `tensorflow-text` for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext processing. Run `pip install tensorflow-text` to install \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    279\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mboth packages or visit https://www.tensorflow.org/install\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    280\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf `tensorflow-text` is already installed, try importing it \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    281\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33min a clean python session. Your installation may have errors.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKerasHub uses `tf.data` and `tensorflow-text` to preprocess text \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    283\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mon all Keras backends. If you are running on Jax or Torch, this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    284\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minstallation does not need GPU support.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     )\n",
      "\u001b[31mImportError\u001b[39m: GemmaTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m     instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:319\u001b[39m, in \u001b[36mOperation.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError when deserializing class \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}.\n\nException encountered: GemmaTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load Gemma 1.1 Instruct 2B model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading Gemma model (this may take a few minutes)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m gemma_lm = \u001b[43mkeras_hub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGemmaCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_preset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemma_1.1_instruct_2b_en\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úì Model loaded successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\models\\task.py:198\u001b[39m, in \u001b[36mTask.from_preset\u001b[39m\u001b[34m(cls, preset, load_weights, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Specifically for classifiers, we never load task weights if\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# num_classes is supplied. We handle this in the task base class because\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# it is the same logic for classifiers regardless of modality (text,\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# images, audio).\u001b[39;00m\n\u001b[32m    197\u001b[39m load_task_weights = \u001b[33m\"\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_task\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_task_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:688\u001b[39m, in \u001b[36mKerasPresetLoader.load_task\u001b[39m\u001b[34m(self, cls, load_weights, load_task_weights, **kwargs)\u001b[39m\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, load_weights, load_task_weights, **kwargs):\n\u001b[32m    685\u001b[39m     \u001b[38;5;66;03m# If there is no `task.json` or it's for the wrong class delegate to the\u001b[39;00m\n\u001b[32m    686\u001b[39m     \u001b[38;5;66;03m# super class loader.\u001b[39;00m\n\u001b[32m    687\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_file_exists(\u001b[38;5;28mself\u001b[39m.preset, TASK_CONFIG_FILE):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_task_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m     task_config = load_json(\u001b[38;5;28mself\u001b[39m.preset, TASK_CONFIG_FILE)\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(check_config_class(task_config), \u001b[38;5;28mcls\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:636\u001b[39m, in \u001b[36mPresetLoader.load_task\u001b[39m\u001b[34m(self, cls, load_weights, load_task_weights, **kwargs)\u001b[39m\n\u001b[32m    632\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mbackbone\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.load_backbone(\n\u001b[32m    633\u001b[39m         backbone_class, load_weights, **backbone_kwargs\n\u001b[32m    634\u001b[39m     )\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.preprocessor_cls:\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_preprocessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocessor_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:773\u001b[39m, in \u001b[36mKerasPresetLoader.load_preprocessor\u001b[39m\u001b[34m(self, cls, config_file, **kwargs)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_preprocessor\u001b[39m(\n\u001b[32m    768\u001b[39m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file=PREPROCESSOR_CONFIG_FILE, **kwargs\n\u001b[32m    769\u001b[39m ):\n\u001b[32m    770\u001b[39m     \u001b[38;5;66;03m# If there is no `preprocessing.json` or it's for the wrong class,\u001b[39;00m\n\u001b[32m    771\u001b[39m     \u001b[38;5;66;03m# delegate to the super class loader.\u001b[39;00m\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_file_exists(\u001b[38;5;28mself\u001b[39m.preset, config_file):\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_preprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m     preprocessor_json = load_json(\u001b[38;5;28mself\u001b[39m.preset, config_file)\n\u001b[32m    775\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(check_config_class(preprocessor_json), \u001b[38;5;28mcls\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:651\u001b[39m, in \u001b[36mPresetLoader.load_preprocessor\u001b[39m\u001b[34m(self, cls, config_file, **kwargs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_preprocessor\u001b[39m(\n\u001b[32m    643\u001b[39m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file=PREPROCESSOR_CONFIG_FILE, **kwargs\n\u001b[32m    644\u001b[39m ):\n\u001b[32m    645\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a prepocessor layer from the preset.\u001b[39;00m\n\u001b[32m    646\u001b[39m \n\u001b[32m    647\u001b[39m \u001b[33;03m    By default, we create a preprocessor from a tokenizer with default\u001b[39;00m\n\u001b[32m    648\u001b[39m \u001b[33;03m    arguments. This allow us to support transformers checkpoints by\u001b[39;00m\n\u001b[32m    649\u001b[39m \u001b[33;03m    only converting the backbone and tokenizer.\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_missing_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\models\\preprocessor.py:201\u001b[39m, in \u001b[36mPreprocessor._add_missing_kwargs\u001b[39m\u001b[34m(cls, loader, kwargs)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fill in required kwargs when loading from preset.\u001b[39;00m\n\u001b[32m    191\u001b[39m \n\u001b[32m    192\u001b[39m \u001b[33;03mThis is a private method hit when loading a preprocessing layer that\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    198\u001b[39m \u001b[33;03mencoders.\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.tokenizer_cls:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtokenizer\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33maudio_converter\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.audio_converter_cls:\n\u001b[32m    203\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33maudio_converter\u001b[39m\u001b[33m\"\u001b[39m] = loader.load_audio_converter(\n\u001b[32m    204\u001b[39m         \u001b[38;5;28mcls\u001b[39m.audio_converter_cls\n\u001b[32m    205\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:671\u001b[39m, in \u001b[36mKerasPresetLoader.load_tokenizer\u001b[39m\u001b[34m(self, cls, config_file, **kwargs)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_tokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file=TOKENIZER_CONFIG_FILE, **kwargs):\n\u001b[32m    670\u001b[39m     tokenizer_config = load_json(\u001b[38;5;28mself\u001b[39m.preset, config_file)\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m     tokenizer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_serialized_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    672\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tokenizer, \u001b[33m\"\u001b[39m\u001b[33mload_preset_assets\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    673\u001b[39m         tokenizer.load_preset_assets(\u001b[38;5;28mself\u001b[39m.preset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:790\u001b[39m, in \u001b[36mKerasPresetLoader._load_serialized_object\u001b[39m\u001b[34m(self, config, **kwargs)\u001b[39m\n\u001b[32m    787\u001b[39m config = set_dtype_in_config(config, dtype)\n\u001b[32m    789\u001b[39m config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m] = {**config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m], **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43msaving\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:735\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    733\u001b[39m     instance = \u001b[38;5;28mcls\u001b[39m.from_config(inner_config)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    738\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m instances (layers, models, etc.) returned by\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    739\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    740\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms `from_config()` method.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    741\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m     )\n\u001b[32m    743\u001b[39m build_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mbuild_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance.built:\n",
      "\u001b[31mTypeError\u001b[39m: <class 'keras_hub.src.models.gemma.gemma_tokenizer.GemmaTokenizer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras_hub.src.models.gemma.gemma_tokenizer', 'class_name': 'GemmaTokenizer', 'config': {'name': 'gemma_tokenizer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'int32'}, 'registered_name': None}, 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}, 'registered_name': 'keras_hub>GemmaTokenizer'}.\n\nException encountered: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}.\n\nException encountered: GemmaTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support."
     ]
    }
   ],
   "source": [
    "# Alternative: Use Gemini API for Local Experimentation\n",
    "# (Complete actual codelabs on Kaggle where Gemma is fully supported)\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    # Initialize Gemini model\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    print(\"‚úì Gemini Pro model initialized\")\n",
    "    print(\"  Use this for local experimentation\")\n",
    "    print(\"  Complete course codelabs on Kaggle!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up Google API key to use Gemini\")\n",
    "    print(\"  Get one from: https://aistudio.google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c65f26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 1: Unit 1 - Introduction to Agents\n",
    "\n",
    "**Date**: November 9, 2025  \n",
    "**Platform**: Complete codelabs on [Kaggle](https://www.kaggle.com)\n",
    "\n",
    "## üìã Today's Assignments\n",
    "\n",
    "### 1. Learning Materials\n",
    "- [ ] **Podcast**: Listen to summary episode for Unit 1\n",
    "- [ ] **Whitepaper**: Read \"Introduction to Agents\"\n",
    "  - Taxonomy of agent capabilities\n",
    "  - Agent Ops discipline\n",
    "  - Interoperability and security\n",
    "- [ ] **Optional**: Add whitepaper to NotebookLM\n",
    "\n",
    "### 2. Hands-On Codelabs (on Kaggle!)\n",
    "- [ ] **Codelab 1**: Build your first agent using Gemini and ADK\n",
    "  - Integrate Google Search for real-time information\n",
    "- [ ] **Codelab 2**: Build multi-agent systems using ADK\n",
    "  - Create teams of specialized agents\n",
    "  - Explore architectural patterns\n",
    "\n",
    "### 3. Tomorrow's Livestream\n",
    "- **Date**: November 10, 11:00 AM PT\n",
    "- **Hosts**: Kanchana Patlolla & Anant Nawalgaria\n",
    "- **Submit questions** on Discord for Kaggle swag!\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Understand AI agent capabilities and taxonomy\n",
    "- Learn ADK (Agent Development Kit) basics\n",
    "- Build conversational agents with tool integration\n",
    "- Create and coordinate multi-agent systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1be80a",
   "metadata": {},
   "source": [
    "## Day 1 Learning Notes\n",
    "\n",
    "### üéß Podcast: Summary Episode\n",
    "*Listen to the podcast and document key takeaways*\n",
    "\n",
    "**Main Topics Covered:**\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "**Key Concepts:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Questions for Further Research:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b0ff2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day 1 Local Experimentation\n",
    "\n",
    "*Use Gemini API to experiment with agent concepts locally while completing official codelabs on Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3575ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Snippet from Codelab 2\n",
    "# Copy your multi-agent system code from Kaggle\n",
    "\n",
    "# Example: Multi-agent architecture\n",
    "\n",
    "\n",
    "# Notes on architecture:\n",
    "# -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369275a",
   "metadata": {},
   "source": [
    "### üë• Codelab 2: Multi-Agent Systems with ADK\n",
    "\n",
    "**Completed on Kaggle**: [Link to your codelab]\n",
    "\n",
    "**System Architecture:**\n",
    "- Number of agents: \n",
    "- Agent roles: \n",
    "- Communication pattern: \n",
    "\n",
    "**Architectural Patterns Explored:**\n",
    "- [ ] Sequential (Agent A ‚Üí Agent B ‚Üí Agent C)\n",
    "- [ ] Parallel (Multiple agents simultaneously)\n",
    "- [ ] Hierarchical (Manager + Workers)\n",
    "- [ ] Other: _______________\n",
    "\n",
    "**What I Built:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Key Learnings:**\n",
    "- Agent specialization\n",
    "- Task routing and delegation\n",
    "- Result synthesis\n",
    "- \n",
    "\n",
    "**Challenges & Solutions:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70920694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Snippet from Codelab 1\n",
    "# Copy interesting code from your Kaggle codelab here\n",
    "\n",
    "# Example: Agent with Google Search integration\n",
    "\n",
    "\n",
    "# Notes on implementation:\n",
    "# -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd80b4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day 1 Kaggle Codelabs\n",
    "\n",
    "### üíª Codelab 1: First Agent with Gemini and ADK\n",
    "\n",
    "**Completed on Kaggle**: [Link to your codelab]\n",
    "\n",
    "**What I Built:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Key Concepts Learned:**\n",
    "- Agent Development Kit (ADK) basics\n",
    "- Tool integration (Google Search)\n",
    "- Prompt engineering for agents\n",
    "- \n",
    "\n",
    "**Challenges Encountered:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Solutions:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a3999",
   "metadata": {},
   "source": [
    "**3. Interoperability & Security**\n",
    "\n",
    "*How do agents work together securely?*\n",
    "\n",
    "**Identity Management:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Constrained Policies:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Security Patterns:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Multi-Agent Coordination:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e2fe1",
   "metadata": {},
   "source": [
    "**2. Agent Ops Discipline**\n",
    "\n",
    "*How do we ensure reliability, governance, and best practices?*\n",
    "\n",
    "**Reliability Considerations:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Governance Frameworks:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Monitoring & Evaluation:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Best Practices:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d0b1c",
   "metadata": {},
   "source": [
    "### üìñ Whitepaper: \"Introduction to Agents\"\n",
    "\n",
    "**1. Taxonomy of Agent Capabilities**\n",
    "\n",
    "*What are the different types and levels of agent capabilities?*\n",
    "\n",
    "**Agent Types:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Capability Levels:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Real-World Examples:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d78e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are AI agents and how do they differ from regular AI models?\n",
      "\n",
      "A: Error: name 'model' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Simple Conversational Agent with Gemini\n",
    "# This demonstrates basic agent concepts locally\n",
    "\n",
    "def simple_gemini_agent(prompt, context=\"\"):\n",
    "    \"\"\"\n",
    "    A simple agent using Gemini API for local experimentation.\n",
    "    \n",
    "    Args:\n",
    "        prompt: User input/question\n",
    "        context: Optional context for the agent\n",
    "    \n",
    "    Returns:\n",
    "        Generated response\n",
    "    \"\"\"\n",
    "    if not GOOGLE_API_KEY:\n",
    "        return \"Please set up Google API key first\"\n",
    "    \n",
    "    if context:\n",
    "        full_prompt = f\"Context: {context}\\n\\nUser: {prompt}\\n\\nProvide a helpful response:\"\n",
    "    else:\n",
    "        full_prompt = prompt\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test the agent\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SIMPLE AGENT TEST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    test_prompt = \"What are AI agents and how do they differ from regular AI models?\"\n",
    "    print(f\"\\nQuestion: {test_prompt}\\n\")\n",
    "    response = simple_gemini_agent(test_prompt)\n",
    "    print(f\"Answer: {response}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up GOOGLE_API_KEY to test the agent\")\n",
    "    print(\"Get one from: https://aistudio.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b88eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Agent with Context Awareness\n",
    "\n",
    "def context_aware_agent(prompt, conversation_history=None):\n",
    "    \"\"\"\n",
    "    An agent that maintains conversation context.\n",
    "    \"\"\"\n",
    "    if not GOOGLE_API_KEY:\n",
    "        return \"Please set up Google API key first\"\n",
    "    \n",
    "    if conversation_history:\n",
    "        context = \"\\n\".join([f\"{role}: {msg}\" for role, msg in conversation_history])\n",
    "        full_prompt = f\"Previous conversation:\\n{context}\\n\\nUser: {prompt}\\n\\nAssistant:\"\n",
    "    else:\n",
    "        full_prompt = prompt\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test context-aware agent\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CONTEXT-AWARE AGENT TEST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Simulate a conversation\n",
    "    history = [\n",
    "        (\"User\", \"My name is Eric and I'm learning about AI agents\"),\n",
    "        (\"Assistant\", \"Nice to meet you, Eric! AI agents are fascinating. What would you like to know?\")\n",
    "    ]\n",
    "    \n",
    "    new_prompt = \"What topics should I focus on first?\"\n",
    "    print(f\"\\nConversation History:\")\n",
    "    for role, msg in history:\n",
    "        print(f\"  {role}: {msg}\")\n",
    "    print(f\"\\nNew Question: {new_prompt}\\n\")\n",
    "    \n",
    "    response = context_aware_agent(new_prompt, history)\n",
    "    print(f\"Answer: {response}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up GOOGLE_API_KEY to test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf39b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day 1 Summary & Reflection\n",
    "\n",
    "### ‚úÖ Completed Today\n",
    "- [ ] Listened to podcast episode\n",
    "- [ ] Read whitepaper on Introduction to Agents\n",
    "- [ ] Completed Codelab 1: First agent with ADK\n",
    "- [ ] Completed Codelab 2: Multi-agent systems\n",
    "- [ ] Experimented with local Gemini agents\n",
    "- [ ] Documented key learnings\n",
    "\n",
    "### üí° Key Takeaways from Day 1\n",
    "\n",
    "**1. Main Insight:**\n",
    "\n",
    "\n",
    "**2. Most Interesting Concept:**\n",
    "\n",
    "\n",
    "**3. Biggest Challenge:**\n",
    "\n",
    "\n",
    "**4. How I Overcame It:**\n",
    "\n",
    "\n",
    "### ü§î Questions for Tomorrow's Livestream\n",
    "\n",
    "**Question 1:**\n",
    "\n",
    "\n",
    "**Question 2:**\n",
    "\n",
    "\n",
    "**Question 3:**\n",
    "\n",
    "\n",
    "### üéØ Ideas for Future Projects\n",
    "\n",
    "**1.**\n",
    "\n",
    "\n",
    "**2.**\n",
    "\n",
    "\n",
    "**3.**\n",
    "\n",
    "\n",
    "### üìÖ Preparation for Day 2\n",
    "- [ ] Review Day 1 notes before livestream\n",
    "- [ ] Prepare questions for Discord\n",
    "- [ ] Ready for 11:00 AM PT livestream tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: Your Own Agent Ideas\n",
    "\n",
    "# Use this cell to experiment with your own agent concepts\n",
    "# Try different prompting strategies, contexts, or behaviors\n",
    "\n",
    "# Your experimentation here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01bfba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 2: Agent Planning and Reasoning\n",
    "\n",
    "**Date**: November 10, 2025\n",
    "\n",
    "## Learning Objectives\n",
    "- Understanding agent planning mechanisms\n",
    "- Implementing reasoning capabilities\n",
    "- Chain-of-thought prompting\n",
    "\n",
    "*(Complete after receiving Day 2 materials)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe991eb",
   "metadata": {},
   "source": [
    "### Day 2 Notes\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2: Planning Agent Template\n",
    "\n",
    "class PlanningAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def plan(self, task):\n",
    "        \"\"\"Break down a task into steps\"\"\"\n",
    "        prompt = f\"Break down this task into steps: {task}\\n\\nSteps:\"\n",
    "        return self.model.generate(prompt, max_length=200)\n",
    "    \n",
    "    def reason(self, question):\n",
    "        \"\"\"Use chain-of-thought reasoning\"\"\"\n",
    "        prompt = f\"Think step by step to answer: {question}\\n\\nReasoning:\"\n",
    "        return self.model.generate(prompt, max_length=250)\n",
    "\n",
    "# Test the planning agent\n",
    "# agent = PlanningAgent(gemma_lm)\n",
    "# result = agent.plan(\"Build a chatbot\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31514efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2: Exercises and Experiments\n",
    "\n",
    "# Add your Day 2 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f09c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 3: Tool Use and Function Calling\n",
    "\n",
    "**Date**: November 11, 2025\n",
    "\n",
    "## Learning Objectives\n",
    "- Enable agents to use external tools\n",
    "- Implement function calling\n",
    "- Create multi-tool agents\n",
    "\n",
    "*(Complete after receiving Day 3 materials)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f168b",
   "metadata": {},
   "source": [
    "### Day 3 Notes\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13999267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 3: Tool-Using Agent Template\n",
    "\n",
    "class ToolAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.tools = {}\n",
    "    \n",
    "    def register_tool(self, name, function, description):\n",
    "        \"\"\"Register a tool that the agent can use\"\"\"\n",
    "        self.tools[name] = {\n",
    "            'function': function,\n",
    "            'description': description\n",
    "        }\n",
    "    \n",
    "    def execute(self, task):\n",
    "        \"\"\"Execute a task using available tools\"\"\"\n",
    "        # Implementation will be completed during Day 3\n",
    "        pass\n",
    "\n",
    "# Example tools\n",
    "def calculator(expression):\n",
    "    \"\"\"Simple calculator tool\"\"\"\n",
    "    try:\n",
    "        return eval(expression)\n",
    "    except:\n",
    "        return \"Error in calculation\"\n",
    "\n",
    "# agent = ToolAgent(gemma_lm)\n",
    "# agent.register_tool(\"calculator\", calculator, \"Performs mathematical calculations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0052567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 3: Exercises and Experiments\n",
    "\n",
    "# Add your Day 3 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f71bd9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 4: Memory and Context Management\n",
    "\n",
    "**Date**: November 12, 2025\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement agent memory systems\n",
    "- Manage conversation context\n",
    "- Build stateful agents\n",
    "\n",
    "*(Complete after receiving Day 4 materials)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0743dc",
   "metadata": {},
   "source": [
    "### Day 4 Notes\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7400a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 4: Agent with Memory Template\n",
    "\n",
    "class MemoryAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.conversation_history = []\n",
    "        self.long_term_memory = {}\n",
    "    \n",
    "    def remember(self, key, value):\n",
    "        \"\"\"Store information in long-term memory\"\"\"\n",
    "        self.long_term_memory[key] = value\n",
    "    \n",
    "    def recall(self, key):\n",
    "        \"\"\"Retrieve information from long-term memory\"\"\"\n",
    "        return self.long_term_memory.get(key)\n",
    "    \n",
    "    def chat(self, message):\n",
    "        \"\"\"Chat with context awareness\"\"\"\n",
    "        self.conversation_history.append(('user', message))\n",
    "        \n",
    "        # Build context from history\n",
    "        context = \"\\n\".join([f\"{role}: {msg}\" for role, msg in self.conversation_history[-5:]])\n",
    "        prompt = f\"{context}\\nassistant:\"\n",
    "        \n",
    "        response = self.model.generate(prompt, max_length=150)\n",
    "        self.conversation_history.append(('assistant', response))\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Test memory agent\n",
    "# mem_agent = MemoryAgent(gemma_lm)\n",
    "# mem_agent.remember(\"user_name\", \"Eric\")\n",
    "# response = mem_agent.chat(\"Hello!\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 4: Exercises and Experiments\n",
    "\n",
    "# Add your Day 4 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee9ed1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 5: Capstone Project\n",
    "\n",
    "**Date**: November 13, 2025\n",
    "\n",
    "## Project Requirements\n",
    "- Apply all concepts learned throughout the week\n",
    "- Build a complete AI agent application\n",
    "- Demonstrate agent capabilities\n",
    "\n",
    "*(Complete after receiving Day 5 materials)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a18a2ac",
   "metadata": {},
   "source": [
    "### Capstone Project Notes\n",
    "\n",
    "**Project Idea**:\n",
    "\n",
    "*Describe your capstone project here*\n",
    "\n",
    "**Requirements**:\n",
    "- [ ] Requirement 1\n",
    "- [ ] Requirement 2\n",
    "- [ ] Requirement 3\n",
    "\n",
    "**Architecture**:\n",
    "\n",
    "*Describe your agent architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Project: Main Implementation\n",
    "\n",
    "# Your capstone project code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Project: Testing and Demonstration\n",
    "\n",
    "# Test your agent here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38ad67",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Course Reflection\n",
    "\n",
    "### What I Learned\n",
    "\n",
    "*Add your reflections after completing the course*\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "*What will you build next?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02434e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Gemma Documentation](https://ai.google.dev/gemma)\n",
    "- [Keras Hub Guide](https://keras.io/keras_hub/)\n",
    "- [Course Materials on Kaggle](https://www.kaggle.com)\n",
    "- [Discord Community](https://discord.gg/kaggle)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
