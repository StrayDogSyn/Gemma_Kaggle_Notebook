{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48178dc0",
   "metadata": {},
   "source": [
    "# AI Agents Development with Gemma\n",
    "\n",
    "This notebook is designed for the 5-Day AI Agents Intensive Course. It will be updated daily as we progress through the course.\n",
    "\n",
    "**Course Dates**: November 9-13, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367e5fe",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "**Important Note:** For the AI Agents course, the **primary platform is Kaggle Notebooks** where all dependencies are pre-configured. This local setup is optional for experimentation.\n",
    "\n",
    "### Platform Options:\n",
    "1. **Kaggle Notebooks** (Recommended) - All dependencies pre-installed\n",
    "2. **Google Colab** - Good for experimentation\n",
    "3. **Local Setup** - Requires Python 3.11 or earlier for tensorflow-text compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb3925a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Python 3.13.7\n",
      "\n",
      "‚ö†Ô∏è Note: tensorflow-text may not be available for Python 3.13 yet.\n",
      "   Options:\n",
      "   1. Use Kaggle notebooks (recommended for this course)\n",
      "   2. Create a Python 3.11 environment locally\n",
      "   3. Use Google Colab for local experimentation\n"
     ]
    }
   ],
   "source": [
    "# Check Python version for compatibility\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "\n",
    "# tensorflow-text compatibility note\n",
    "if sys.version_info >= (3, 13):\n",
    "    print(\"\\n‚ö†Ô∏è Note: tensorflow-text may not be available for Python 3.13 yet.\")\n",
    "    print(\"   Options:\")\n",
    "    print(\"   1. Use Kaggle notebooks (recommended for this course)\")\n",
    "    print(\"   2. Create a Python 3.11 environment locally\")\n",
    "    print(\"   3. Use Google Colab for local experimentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd63ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (for local experimentation only)\n",
    "# Note: The course codelabs should be completed on Kaggle platform\n",
    "# tensorflow-text requires Python <=3.12 currently\n",
    "\n",
    "%pip install -q -U google-generativeai python-dotenv\n",
    "\n",
    "# Uncomment below if using Python 3.11 or earlier:\n",
    "# %pip install -q -U tensorflow tensorflow-text keras-hub keras jax[cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dacb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete - 2025-11-09 19:49:00\n",
      "Keras backend: jax\n"
     ]
    }
   ],
   "source": [
    "# Basic imports for notebook\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    print(f\"‚úì Setup complete - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"‚úì google-generativeai loaded\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Run the installation cell above first\")\n",
    "\n",
    "# Optional: These are only needed if using Python 3.11 or earlier with local Gemma\n",
    "try:\n",
    "    import numpy as np\n",
    "    os.environ['KERAS_BACKEND'] = 'jax'\n",
    "    import keras\n",
    "    import keras_hub\n",
    "    print(f\"‚úì Keras backend: {keras.backend.backend()}\")\n",
    "    print(\"  (Optional - only needed for local Gemma experimentation)\")\n",
    "except ImportError:\n",
    "    print(\"‚ÑπÔ∏è  Keras/KerasHub not installed (not required for this course)\")\n",
    "    print(\"   Complete all codelabs on Kaggle where dependencies are pre-configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46166c",
   "metadata": {},
   "source": [
    "## API Configuration\n",
    "\n",
    "Configure Google AI Studio API for additional model access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea6bfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using local .env file\n",
      "‚úì Google AI API configured\n"
     ]
    }
   ],
   "source": [
    "# For Kaggle: Use Kaggle Secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    print(\"‚úì Using Kaggle Secrets\")\n",
    "except:\n",
    "    # For local: Use environment variables\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    print(\"‚úì Using local .env file\")\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    print(\"‚úì Google AI API configured\")\n",
    "else:\n",
    "    print(\"‚ö† Warning: API key not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f1360",
   "metadata": {},
   "source": [
    "## Gemma Model Setup\n",
    "\n",
    "**‚ö†Ô∏è Local Limitation:** Gemma via KerasHub requires `tensorflow-text`, which is not available for Python 3.13+ on Windows.\n",
    "\n",
    "### ‚úÖ Recommended Approach:\n",
    "- **Complete all course codelabs on [Kaggle](https://www.kaggle.com)** where Gemma works perfectly\n",
    "- **Use this notebook** for notes, documentation, and Gemini API experiments\n",
    "\n",
    "### üí° Alternative: Gemini API\n",
    "Below we'll use the Gemini API (which you have configured) to experiment with agent concepts locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gemma model (this may take a few minutes)...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<class 'keras_hub.src.models.gemma.gemma_tokenizer.GemmaTokenizer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras_hub.src.models.gemma.gemma_tokenizer', 'class_name': 'GemmaTokenizer', 'config': {'name': 'gemma_tokenizer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'int32'}, 'registered_name': None}, 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}, 'registered_name': 'keras_hub>GemmaTokenizer'}.\n\nException encountered: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}.\n\nException encountered: GemmaTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:317\u001b[39m, in \u001b[36mOperation.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\models\\gemma\\gemma_tokenizer.py:78\u001b[39m, in \u001b[36mGemmaTokenizer.__init__\u001b[39m\u001b[34m(self, proto, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m._add_special_token(\u001b[33m\"\u001b[39m\u001b[33m<pad>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpad_token\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\tokenizers\\sentence_piece_tokenizer.py:111\u001b[39m, in \u001b[36mSentencePieceTokenizer.__init__\u001b[39m\u001b[34m(self, proto, sequence_length, dtype, add_bos, add_eos, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOutput dtype must be an integer type or a string. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    108\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.proto = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\tokenizers\\tokenizer.py:70\u001b[39m, in \u001b[36mTokenizer.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m.config_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mconfig_file\u001b[39m\u001b[33m\"\u001b[39m, TOKENIZER_CONFIG_FILE)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mself\u001b[39m.file_assets = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\layers\\preprocessing\\preprocessing_layer.py:10\u001b[39m, in \u001b[36mPreprocessingLayer.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[43massert_tf_libs_installed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\tensor_utils.py:276\u001b[39m, in \u001b[36massert_tf_libs_installed\u001b[39m\u001b[34m(symbol_name)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tf_text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m tf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    277\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires `tensorflow` and `tensorflow-text` for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext processing. Run `pip install tensorflow-text` to install \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    279\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mboth packages or visit https://www.tensorflow.org/install\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    280\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf `tensorflow-text` is already installed, try importing it \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    281\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33min a clean python session. Your installation may have errors.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKerasHub uses `tf.data` and `tensorflow-text` to preprocess text \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    283\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mon all Keras backends. If you are running on Jax or Torch, this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    284\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minstallation does not need GPU support.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     )\n",
      "\u001b[31mImportError\u001b[39m: GemmaTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m     instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:319\u001b[39m, in \u001b[36mOperation.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError when deserializing class \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}.\n\nException encountered: GemmaTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load Gemma 1.1 Instruct 2B model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading Gemma model (this may take a few minutes)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m gemma_lm = \u001b[43mkeras_hub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGemmaCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_preset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemma_1.1_instruct_2b_en\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úì Model loaded successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\models\\task.py:198\u001b[39m, in \u001b[36mTask.from_preset\u001b[39m\u001b[34m(cls, preset, load_weights, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Specifically for classifiers, we never load task weights if\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# num_classes is supplied. We handle this in the task base class because\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# it is the same logic for classifiers regardless of modality (text,\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# images, audio).\u001b[39;00m\n\u001b[32m    197\u001b[39m load_task_weights = \u001b[33m\"\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_task\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_task_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:688\u001b[39m, in \u001b[36mKerasPresetLoader.load_task\u001b[39m\u001b[34m(self, cls, load_weights, load_task_weights, **kwargs)\u001b[39m\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, load_weights, load_task_weights, **kwargs):\n\u001b[32m    685\u001b[39m     \u001b[38;5;66;03m# If there is no `task.json` or it's for the wrong class delegate to the\u001b[39;00m\n\u001b[32m    686\u001b[39m     \u001b[38;5;66;03m# super class loader.\u001b[39;00m\n\u001b[32m    687\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_file_exists(\u001b[38;5;28mself\u001b[39m.preset, TASK_CONFIG_FILE):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_task_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m     task_config = load_json(\u001b[38;5;28mself\u001b[39m.preset, TASK_CONFIG_FILE)\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(check_config_class(task_config), \u001b[38;5;28mcls\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:636\u001b[39m, in \u001b[36mPresetLoader.load_task\u001b[39m\u001b[34m(self, cls, load_weights, load_task_weights, **kwargs)\u001b[39m\n\u001b[32m    632\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mbackbone\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.load_backbone(\n\u001b[32m    633\u001b[39m         backbone_class, load_weights, **backbone_kwargs\n\u001b[32m    634\u001b[39m     )\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.preprocessor_cls:\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_preprocessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocessor_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:773\u001b[39m, in \u001b[36mKerasPresetLoader.load_preprocessor\u001b[39m\u001b[34m(self, cls, config_file, **kwargs)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_preprocessor\u001b[39m(\n\u001b[32m    768\u001b[39m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file=PREPROCESSOR_CONFIG_FILE, **kwargs\n\u001b[32m    769\u001b[39m ):\n\u001b[32m    770\u001b[39m     \u001b[38;5;66;03m# If there is no `preprocessing.json` or it's for the wrong class,\u001b[39;00m\n\u001b[32m    771\u001b[39m     \u001b[38;5;66;03m# delegate to the super class loader.\u001b[39;00m\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_file_exists(\u001b[38;5;28mself\u001b[39m.preset, config_file):\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_preprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m     preprocessor_json = load_json(\u001b[38;5;28mself\u001b[39m.preset, config_file)\n\u001b[32m    775\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(check_config_class(preprocessor_json), \u001b[38;5;28mcls\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:651\u001b[39m, in \u001b[36mPresetLoader.load_preprocessor\u001b[39m\u001b[34m(self, cls, config_file, **kwargs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_preprocessor\u001b[39m(\n\u001b[32m    643\u001b[39m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file=PREPROCESSOR_CONFIG_FILE, **kwargs\n\u001b[32m    644\u001b[39m ):\n\u001b[32m    645\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a prepocessor layer from the preset.\u001b[39;00m\n\u001b[32m    646\u001b[39m \n\u001b[32m    647\u001b[39m \u001b[33;03m    By default, we create a preprocessor from a tokenizer with default\u001b[39;00m\n\u001b[32m    648\u001b[39m \u001b[33;03m    arguments. This allow us to support transformers checkpoints by\u001b[39;00m\n\u001b[32m    649\u001b[39m \u001b[33;03m    only converting the backbone and tokenizer.\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_missing_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\models\\preprocessor.py:201\u001b[39m, in \u001b[36mPreprocessor._add_missing_kwargs\u001b[39m\u001b[34m(cls, loader, kwargs)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fill in required kwargs when loading from preset.\u001b[39;00m\n\u001b[32m    191\u001b[39m \n\u001b[32m    192\u001b[39m \u001b[33;03mThis is a private method hit when loading a preprocessing layer that\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    198\u001b[39m \u001b[33;03mencoders.\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.tokenizer_cls:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtokenizer\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33maudio_converter\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.audio_converter_cls:\n\u001b[32m    203\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33maudio_converter\u001b[39m\u001b[33m\"\u001b[39m] = loader.load_audio_converter(\n\u001b[32m    204\u001b[39m         \u001b[38;5;28mcls\u001b[39m.audio_converter_cls\n\u001b[32m    205\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:671\u001b[39m, in \u001b[36mKerasPresetLoader.load_tokenizer\u001b[39m\u001b[34m(self, cls, config_file, **kwargs)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_tokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m, config_file=TOKENIZER_CONFIG_FILE, **kwargs):\n\u001b[32m    670\u001b[39m     tokenizer_config = load_json(\u001b[38;5;28mself\u001b[39m.preset, config_file)\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m     tokenizer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_serialized_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    672\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tokenizer, \u001b[33m\"\u001b[39m\u001b[33mload_preset_assets\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    673\u001b[39m         tokenizer.load_preset_assets(\u001b[38;5;28mself\u001b[39m.preset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras_hub\\src\\utils\\preset_utils.py:790\u001b[39m, in \u001b[36mKerasPresetLoader._load_serialized_object\u001b[39m\u001b[34m(self, config, **kwargs)\u001b[39m\n\u001b[32m    787\u001b[39m config = set_dtype_in_config(config, dtype)\n\u001b[32m    789\u001b[39m config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m] = {**config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m], **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43msaving\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EHunt\\Repos\\Projects\\Gemma_Kaggle_Notebook\\.venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:735\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    733\u001b[39m     instance = \u001b[38;5;28mcls\u001b[39m.from_config(inner_config)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    738\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m instances (layers, models, etc.) returned by\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    739\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    740\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms `from_config()` method.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    741\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m     )\n\u001b[32m    743\u001b[39m build_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mbuild_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance.built:\n",
      "\u001b[31mTypeError\u001b[39m: <class 'keras_hub.src.models.gemma.gemma_tokenizer.GemmaTokenizer'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras_hub.src.models.gemma.gemma_tokenizer', 'class_name': 'GemmaTokenizer', 'config': {'name': 'gemma_tokenizer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'int32'}, 'registered_name': None}, 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}, 'registered_name': 'keras_hub>GemmaTokenizer'}.\n\nException encountered: Error when deserializing class 'GemmaTokenizer' using config={'name': 'gemma_tokenizer', 'trainable': True, 'dtype': 'int32', 'config_file': 'tokenizer.json', 'proto': None, 'sequence_length': None, 'add_bos': False, 'add_eos': False}.\n\nException encountered: GemmaTokenizer requires `tensorflow` and `tensorflow-text` for text processing. Run `pip install tensorflow-text` to install both packages or visit https://www.tensorflow.org/install\n\nIf `tensorflow-text` is already installed, try importing it in a clean python session. Your installation may have errors.\n\nKerasHub uses `tf.data` and `tensorflow-text` to preprocess text on all Keras backends. If you are running on Jax or Torch, this installation does not need GPU support."
     ]
    }
   ],
   "source": [
    "# Alternative: Use Gemini API for Local Experimentation\n",
    "# (Complete actual codelabs on Kaggle where Gemma is fully supported)\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    # Initialize Gemini model\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    print(\"‚úì Gemini Pro model initialized\")\n",
    "    print(\"  Use this for local experimentation\")\n",
    "    print(\"  Complete course codelabs on Kaggle!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up Google API key to use Gemini\")\n",
    "    print(\"  Get one from: https://aistudio.google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c65f26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 1: Unit 1 - Introduction to Agents\n",
    "\n",
    "**Date**: November 9, 2025  \n",
    "**Platform**: Complete codelabs on [Kaggle](https://www.kaggle.com)\n",
    "\n",
    "## üìã Today's Assignments\n",
    "\n",
    "### 1. Learning Materials\n",
    "- [ ] **Podcast**: Listen to summary episode for Unit 1\n",
    "- [ ] **Whitepaper**: Read \"Introduction to Agents\"\n",
    "  - Taxonomy of agent capabilities\n",
    "  - Agent Ops discipline\n",
    "  - Interoperability and security\n",
    "- [ ] **Optional**: Add whitepaper to NotebookLM\n",
    "\n",
    "### 2. Hands-On Codelabs (on Kaggle!)\n",
    "- [ ] **Codelab 1**: Build your first agent using Gemini and ADK\n",
    "  - Integrate Google Search for real-time information\n",
    "- [ ] **Codelab 2**: Build multi-agent systems using ADK\n",
    "  - Create teams of specialized agents\n",
    "  - Explore architectural patterns\n",
    "\n",
    "### 3. Tomorrow's Livestream\n",
    "- **Date**: November 10, 11:00 AM PT\n",
    "- **Hosts**: Kanchana Patlolla & Anant Nawalgaria\n",
    "- **Submit questions** on Discord for Kaggle swag!\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Understand AI agent capabilities and taxonomy\n",
    "- Learn ADK (Agent Development Kit) basics\n",
    "- Build conversational agents with tool integration\n",
    "- Create and coordinate multi-agent systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1be80a",
   "metadata": {},
   "source": [
    "## Day 1 Learning Notes\n",
    "\n",
    "### üéß Podcast: Summary Episode\n",
    "*Listen to the podcast and document key takeaways*\n",
    "\n",
    "**Main Topics Covered:**\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "**Key Concepts:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Questions for Further Research:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27884db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Core Concepts & Working Examples\n",
    "\n",
    "Before diving into Kaggle codelabs, let's build a solid foundation with working code examples you can run locally.\n",
    "\n",
    "### üìö Learning Path\n",
    "1. **Example 1**: Simple Agent - Understand the basics\n",
    "2. **Example 2**: Context-Aware Agent - Add memory\n",
    "3. **Example 3**: Self-Evaluating Agent - Quality control  \n",
    "4. **Example 4**: LLM vs Agent Comparison - See the difference\n",
    "5. **Exercise Time**: Apply what you learned\n",
    "\n",
    "**üëâ Tip**: Run each cell and observe the output. Modify the code to experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f4c2764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXAMPLE 1: Simple Agent\n",
      "============================================================\n",
      "ü§ñ Agent Processing...\n",
      "  üëÅÔ∏è  Perceived: Message at 20:38, 0 history items\n",
      "  üß† Planned: generate_response ‚Üí store_in_memory\n",
      "  ‚ö° Acted: Generated 341 character response\n",
      "  ‚úÖ Evaluated: Quality = good\n",
      "\n",
      "üí¨ Assistant: Hi there! That's a fascinating and rapidly evolving topic. AI agents are truly at the heart of many exciting developments in AI.\n",
      "\n",
      "What aspects of AI agents are you most curious about today? Are you looking for a general overview, specific examples, or maybe diving into their architecture or capabilities? I'm happy to help in any way I can!\n",
      "\n",
      "ü§ñ Agent Processing...\n",
      "  üëÅÔ∏è  Perceived: Message at 20:38, 2 history items\n",
      "  üß† Planned: generate_response ‚Üí store_in_memory\n",
      "  ‚ö° Acted: Generated 341 character response\n",
      "  ‚úÖ Evaluated: Quality = good\n",
      "\n",
      "üí¨ Assistant: Hi there! That's a fascinating and rapidly evolving topic. AI agents are truly at the heart of many exciting developments in AI.\n",
      "\n",
      "What aspects of AI agents are you most curious about today? Are you looking for a general overview, specific examples, or maybe diving into their architecture or capabilities? I'm happy to help in any way I can!\n",
      "\n",
      "ü§ñ Agent Processing...\n",
      "  üëÅÔ∏è  Perceived: Message at 20:38, 2 history items\n",
      "  üß† Planned: generate_response ‚Üí store_in_memory\n",
      "  ‚ö° Acted: Generated 977 character response\n",
      "  ‚úÖ Evaluated: Quality = good\n",
      "\n",
      "üí¨ Assistant: That's a great question and a smart way to approach learning something new!\n",
      "\n",
      "I'd suggest we start with the **fundamental definition and the core cycle of an AI agent.**\n",
      "\n",
      "If you understand:\n",
      "\n",
      "1.  **What an AI agent *is*:** Essentially, anything that can *perceive* its environment through sensors and *act* upon that environment through actuators.\n",
      "2.  **Its basic operational cycle:** **Perceive -> Process/Decide -> Act.**\n",
      "\n",
      "...you'll have a really solid foundation. This simple loop is at the heart of even the most complex agents.\n",
      "\n",
      "Once we've got that down, we can easily move on to more specific aspects like:\n",
      "*   Different **types** of agents (simple reflex, goal-based, learning agents, etc.)\n",
      "*   How to **characterize** an agent's task environment using the PEAS description (Performance, Environment, Actuators, Sensors).\n",
      "*   Their **architecture** and specific **capabilities**.\n",
      "\n",
      "So, does starting with \"What is an AI agent, and what's its basic loop?\" sound good to you?\n",
      "\n",
      "============================================================\n",
      "  ‚ö° Acted: Generated 977 character response\n",
      "  ‚úÖ Evaluated: Quality = good\n",
      "\n",
      "üí¨ Assistant: That's a great question and a smart way to approach learning something new!\n",
      "\n",
      "I'd suggest we start with the **fundamental definition and the core cycle of an AI agent.**\n",
      "\n",
      "If you understand:\n",
      "\n",
      "1.  **What an AI agent *is*:** Essentially, anything that can *perceive* its environment through sensors and *act* upon that environment through actuators.\n",
      "2.  **Its basic operational cycle:** **Perceive -> Process/Decide -> Act.**\n",
      "\n",
      "...you'll have a really solid foundation. This simple loop is at the heart of even the most complex agents.\n",
      "\n",
      "Once we've got that down, we can easily move on to more specific aspects like:\n",
      "*   Different **types** of agents (simple reflex, goal-based, learning agents, etc.)\n",
      "*   How to **characterize** an agent's task environment using the PEAS description (Performance, Environment, Actuators, Sensors).\n",
      "*   Their **architecture** and specific **capabilities**.\n",
      "\n",
      "So, does starting with \"What is an AI agent, and what's its basic loop?\" sound good to you?\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "### EXAMPLE 1: Simple Agent - The Foundation\n",
    "# This demonstrates the basic 5-component agent structure\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"A basic agent with perceive ‚Üí plan ‚Üí act ‚Üí evaluate ‚Üí respond cycle\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def perceive(self, user_message: str) -> Dict[str, Any]:\n",
    "        \"\"\"Gather information about current state\"\"\"\n",
    "        return {\n",
    "            \"user_message\": user_message,\n",
    "            \"history\": self.conversation_history[-3:],  # Last 3 turns\n",
    "            \"timestamp\": datetime.now().strftime(\"%H:%M\"),\n",
    "        }\n",
    "    \n",
    "    def plan(self, perception: Dict) -> List[str]:\n",
    "        \"\"\"Decide what to do\"\"\"\n",
    "        # Simple planning: always generate a response\n",
    "        return [\"generate_response\", \"store_in_memory\"]\n",
    "    \n",
    "    def act(self, plan: List[str], perception: Dict) -> str:\n",
    "        \"\"\"Execute the plan\"\"\"\n",
    "        response = None\n",
    "        \n",
    "        for action in plan:\n",
    "            if action == \"generate_response\":\n",
    "                # Build context from history\n",
    "                context = \"\\n\".join([\n",
    "                    f\"{msg['role']}: {msg['content']}\" \n",
    "                    for msg in perception[\"history\"]\n",
    "                ])\n",
    "                \n",
    "                prompt = f\"\"\"Previous conversation:\n",
    "{context}\n",
    "\n",
    "User ({perception['timestamp']}): {perception['user_message']}\n",
    "\n",
    "Respond naturally and helpfully:\"\"\"\n",
    "                \n",
    "                response = self.model.generate_content(prompt).text\n",
    "                \n",
    "            elif action == \"store_in_memory\":\n",
    "                self.conversation_history.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": perception[\"user_message\"]\n",
    "                })\n",
    "                self.conversation_history.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": response\n",
    "                })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def evaluate(self, response: str) -> Dict:\n",
    "        \"\"\"Check if response is adequate\"\"\"\n",
    "        # Simple evaluation: check length and content\n",
    "        if len(response) < 10:\n",
    "            return {\"quality\": \"poor\", \"reason\": \"Too short\"}\n",
    "        elif \"error\" in response.lower() or \"cannot\" in response.lower():\n",
    "            return {\"quality\": \"needs_improvement\", \"reason\": \"Negative response\"}\n",
    "        else:\n",
    "            return {\"quality\": \"good\", \"reason\": \"Adequate length and content\"}\n",
    "    \n",
    "    def process(self, user_message: str) -> str:\n",
    "        \"\"\"Main agent loop\"\"\"\n",
    "        print(\"ü§ñ Agent Processing...\")\n",
    "        \n",
    "        # 1. PERCEIVE\n",
    "        state = self.perceive(user_message)\n",
    "        print(f\"  üëÅÔ∏è  Perceived: Message at {state['timestamp']}, {len(state['history'])} history items\")\n",
    "        \n",
    "        # 2. PLAN\n",
    "        plan = self.plan(state)\n",
    "        print(f\"  üß† Planned: {' ‚Üí '.join(plan)}\")\n",
    "        \n",
    "        # 3. ACT\n",
    "        response = self.act(plan, state)\n",
    "        print(f\"  ‚ö° Acted: Generated {len(response)} character response\")\n",
    "        \n",
    "        # 4. EVALUATE\n",
    "        evaluation = self.evaluate(response)\n",
    "        print(f\"  ‚úÖ Evaluated: Quality = {evaluation['quality']}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "\n",
    "# Test the agent\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXAMPLE 1: Simple Agent\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    agent = SimpleAgent(model)\n",
    "    \n",
    "    # Conversation test\n",
    "    response1 = agent.process(\"Hi! I'm learning about AI agents today.\")\n",
    "    print(f\"\\nüí¨ Assistant: {response1}\\n\")\n",
    "    \n",
    "    response2 = agent.process(\"What should I focus on first?\")\n",
    "    print(f\"\\nüí¨ Assistant: {response2}\\n\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Configure GOOGLE_API_KEY first (run Cell 7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6fd70ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXAMPLE 2: Context-Aware Agent\n",
      "============================================================\n",
      "\n",
      "üí¨ User: Hi! My name is Eric and I'm learning about AI agents.\n",
      "ü§ñ Assistant: Hi Eric! That's a fantastic topic to be learning about ‚Äì AI agents are a really exciting and rapidly evolving area in artificial intelligence.\n",
      "\n",
      "Welcome! What specifically about AI agents has caught your interest, or what are you curious about learning first? I'd be happy to help explain concepts, discuss applications, or point you to resources!\n",
      "\n",
      "üìä Agent learned: {'preferences': {}, 'facts': ['Name: Hi!'], 'interests': []}\n",
      "\n",
      "üí¨ User: What topics should I study?\n",
      "ü§ñ Assistant: Hi Eric! That's a fantastic topic to be learning about ‚Äì AI agents are a really exciting and rapidly evolving area in artificial intelligence.\n",
      "\n",
      "Welcome! What specifically about AI agents has caught your interest, or what are you curious about learning first? I'd be happy to help explain concepts, discuss applications, or point you to resources!\n",
      "\n",
      "üìä Agent learned: {'preferences': {}, 'facts': ['Name: Hi!'], 'interests': []}\n",
      "\n",
      "üí¨ User: What topics should I study?\n",
      "ü§ñ Assistant: That's a fantastic question, but also a very broad one! To give you the most helpful recommendations, I need a little more context.\n",
      "\n",
      "**Please tell me about:**\n",
      "\n",
      "1.  **What is your goal for studying?** (e.g., career change, getting a promotion, personal growth, academic success, passing an exam, a new hobby, understanding the world better, solving a specific problem?)\n",
      "2.  **What are your current interests?** (Even vague ones can help ‚Äì e.g., \"I like technology,\" \"I'm interested in how people think,\" \"I enjoy creating things,\" \"I want to be healthier.\")\n",
      "3.  **What's your current situation?** (e.g., high school student, college student, working professional, retired, looking for a job?)\n",
      "4.  **How much time and effort are you willing to dedicate?** (e.g., a few hours a week, a deep dive for several months, a full-time commitment?)\n",
      "5.  **What's your current level of knowledge/experience?** (e.g., beginner in everything, some background in XYZ, expert in ABC looking to branch out?)\n",
      "\n",
      "---\n",
      "\n",
      "**In the meantime, here are some broad categories and popular topics people study, which might spark some ideas:**\n",
      "\n",
      "### **I. Career & Professional Development**\n",
      "\n",
      "*   **Technology & Data:**\n",
      "    *   **Programming Languages:** Python (data science, web dev, AI), JavaScript (web development), C++, Java, Go, Rust.\n",
      "    *   **Data Science & Analytics:** SQL, Statistics, Machine Learning, Data Visualization, Big Data.\n",
      "    *   **Web Development:** Frontend (HTML, CSS, JavaScript, React/Vue/Angular), Backend (Node.js, Python/Django, Ruby/Rails), Full-stack.\n",
      "    *   **Cloud Computing:** AWS, Azure, Google Cloud Platform certifications.\n",
      "    *   **Cybersecurity:** Network security, ethical hacking, digital forensics.\n",
      "    *   **Artificial Intelligence & Machine Learning:** Deep Learning, NLP (Natural Language Processing), Computer Vision.\n",
      "    *   **UI/UX Design:** User interface and user experience design principles and tools.\n",
      "    *   **Project Management:** Agile, Scrum, PMP certification.\n",
      "*   **Business & Finance:**\n",
      "    *   **Digital Marketing:** SEO, SEM, Content Marketing, Social Media Marketing, Email Marketing.\n",
      "    *   **Finance & Investing:** Personal finance, stock market, real estate, financial analysis.\n",
      "    *   **Entrepreneurship:** Business planning, startup growth, fundraising.\n",
      "    *   **Sales & Negotiation:** Effective communication, closing deals.\n",
      "    *   **Leadership & Management:** Team building, strategic planning.\n",
      "*   **Communication & Soft Skills:**\n",
      "    *   **Public Speaking & Presentation Skills.**\n",
      "    *   **Effective Writing:** Business writing, copywriting, technical writing.\n",
      "    *   **Emotional Intelligence & Active Listening.**\n",
      "    *   **Critical Thinking & Problem Solving.**\n",
      "    *   **Time Management & Productivity.**\n",
      "\n",
      "### **II. Academic & General Knowledge**\n",
      "\n",
      "*   **Science:** Physics, Chemistry, Biology, Environmental Science, Astronomy.\n",
      "*   **Mathematics:** Algebra, Calculus, Statistics, Discrete Math.\n",
      "*   **History:** World History, specific regions (e.g., European, Asian), periods (e.g., Ancient, Medieval, Modern).\n",
      "*   **Literature:** Classics, specific genres (e.g., fantasy, sci-fi), contemporary authors.\n",
      "*   **Languages:** Spanish, French, Mandarin, German, Japanese, ASL, etc.\n",
      "*   **Social Sciences:** Psychology, Sociology, Economics, Political Science, Anthropology.\n",
      "*   **Philosophy:** Ethics, Logic, Metaphysics, Epistemology.\n",
      "*   **Arts & Humanities:** Art History, Music Theory, Creative Writing.\n",
      "\n",
      "### **III. Personal Development & Life Skills**\n",
      "\n",
      "*   **Financial Literacy:** Budgeting, saving, investing, debt management.\n",
      "*   **Health & Wellness:** Nutrition, exercise science, mindfulness, stress management.\n",
      "*   **Cooking & Baking:** Culinary skills, specific cuisines.\n",
      "*   **DIY & Home Improvement:** Basic carpentry, plumbing, electrical, gardening.\n",
      "*   **Creative Hobbies:** Drawing, painting, photography, playing a musical instrument, pottery.\n",
      "*   **Survival Skills:** First aid, outdoor navigation.\n",
      "*   **Mindfulness & Meditation:** Techniques for focus and well-being.\n",
      "\n",
      "---\n",
      "\n",
      "Once you give me a bit more detail about **why** you want to study and **what interests you**, I can offer much more tailored and actionable suggestions!\n",
      "\n",
      "üí¨ User: I love Python programming!\n",
      "ü§ñ Assistant: That's a fantastic question, but also a very broad one! To give you the most helpful recommendations, I need a little more context.\n",
      "\n",
      "**Please tell me about:**\n",
      "\n",
      "1.  **What is your goal for studying?** (e.g., career change, getting a promotion, personal growth, academic success, passing an exam, a new hobby, understanding the world better, solving a specific problem?)\n",
      "2.  **What are your current interests?** (Even vague ones can help ‚Äì e.g., \"I like technology,\" \"I'm interested in how people think,\" \"I enjoy creating things,\" \"I want to be healthier.\")\n",
      "3.  **What's your current situation?** (e.g., high school student, college student, working professional, retired, looking for a job?)\n",
      "4.  **How much time and effort are you willing to dedicate?** (e.g., a few hours a week, a deep dive for several months, a full-time commitment?)\n",
      "5.  **What's your current level of knowledge/experience?** (e.g., beginner in everything, some background in XYZ, expert in ABC looking to branch out?)\n",
      "\n",
      "---\n",
      "\n",
      "**In the meantime, here are some broad categories and popular topics people study, which might spark some ideas:**\n",
      "\n",
      "### **I. Career & Professional Development**\n",
      "\n",
      "*   **Technology & Data:**\n",
      "    *   **Programming Languages:** Python (data science, web dev, AI), JavaScript (web development), C++, Java, Go, Rust.\n",
      "    *   **Data Science & Analytics:** SQL, Statistics, Machine Learning, Data Visualization, Big Data.\n",
      "    *   **Web Development:** Frontend (HTML, CSS, JavaScript, React/Vue/Angular), Backend (Node.js, Python/Django, Ruby/Rails), Full-stack.\n",
      "    *   **Cloud Computing:** AWS, Azure, Google Cloud Platform certifications.\n",
      "    *   **Cybersecurity:** Network security, ethical hacking, digital forensics.\n",
      "    *   **Artificial Intelligence & Machine Learning:** Deep Learning, NLP (Natural Language Processing), Computer Vision.\n",
      "    *   **UI/UX Design:** User interface and user experience design principles and tools.\n",
      "    *   **Project Management:** Agile, Scrum, PMP certification.\n",
      "*   **Business & Finance:**\n",
      "    *   **Digital Marketing:** SEO, SEM, Content Marketing, Social Media Marketing, Email Marketing.\n",
      "    *   **Finance & Investing:** Personal finance, stock market, real estate, financial analysis.\n",
      "    *   **Entrepreneurship:** Business planning, startup growth, fundraising.\n",
      "    *   **Sales & Negotiation:** Effective communication, closing deals.\n",
      "    *   **Leadership & Management:** Team building, strategic planning.\n",
      "*   **Communication & Soft Skills:**\n",
      "    *   **Public Speaking & Presentation Skills.**\n",
      "    *   **Effective Writing:** Business writing, copywriting, technical writing.\n",
      "    *   **Emotional Intelligence & Active Listening.**\n",
      "    *   **Critical Thinking & Problem Solving.**\n",
      "    *   **Time Management & Productivity.**\n",
      "\n",
      "### **II. Academic & General Knowledge**\n",
      "\n",
      "*   **Science:** Physics, Chemistry, Biology, Environmental Science, Astronomy.\n",
      "*   **Mathematics:** Algebra, Calculus, Statistics, Discrete Math.\n",
      "*   **History:** World History, specific regions (e.g., European, Asian), periods (e.g., Ancient, Medieval, Modern).\n",
      "*   **Literature:** Classics, specific genres (e.g., fantasy, sci-fi), contemporary authors.\n",
      "*   **Languages:** Spanish, French, Mandarin, German, Japanese, ASL, etc.\n",
      "*   **Social Sciences:** Psychology, Sociology, Economics, Political Science, Anthropology.\n",
      "*   **Philosophy:** Ethics, Logic, Metaphysics, Epistemology.\n",
      "*   **Arts & Humanities:** Art History, Music Theory, Creative Writing.\n",
      "\n",
      "### **III. Personal Development & Life Skills**\n",
      "\n",
      "*   **Financial Literacy:** Budgeting, saving, investing, debt management.\n",
      "*   **Health & Wellness:** Nutrition, exercise science, mindfulness, stress management.\n",
      "*   **Cooking & Baking:** Culinary skills, specific cuisines.\n",
      "*   **DIY & Home Improvement:** Basic carpentry, plumbing, electrical, gardening.\n",
      "*   **Creative Hobbies:** Drawing, painting, photography, playing a musical instrument, pottery.\n",
      "*   **Survival Skills:** First aid, outdoor navigation.\n",
      "*   **Mindfulness & Meditation:** Techniques for focus and well-being.\n",
      "\n",
      "---\n",
      "\n",
      "Once you give me a bit more detail about **why** you want to study and **what interests you**, I can offer much more tailored and actionable suggestions!\n",
      "\n",
      "üí¨ User: I love Python programming!\n",
      "ü§ñ Assistant: That's fantastic to hear! Python is truly a versatile and powerful language, and its readability, vast ecosystem of libraries, and incredible community make it a favorite for many.\n",
      "\n",
      "What specific aspects do you enjoy most about it, or what kind of projects do you love working on with Python?\n",
      "\n",
      "If you're looking for ways to deepen your skills or explore new areas, here are some ideas:\n",
      "\n",
      "1.  **Dive Deeper into Specific Areas:**\n",
      "    *   **Web Development:** Explore frameworks like **Django** (full-featured) or **Flask** (micro-framework) to build web applications.\n",
      "    *   **Data Science & Machine Learning:** Get into **NumPy**, **Pandas** for data manipulation, and libraries like **Scikit-learn**, **TensorFlow**, or **PyTorch** for AI.\n",
      "    *   **Automation & Scripting:** Learn how to automate repetitive tasks on your computer or interact with APIs.\n",
      "    *   **Game Development:** Check out **Pygame** to create your own 2D games.\n",
      "    *   **GUI Development:** Explore **Tkinter**, **PyQt**, or **Kivy** for creating desktop applications.\n",
      "\n",
      "2.  **Build Personal Projects:** Nothing solidifies learning like building things. Think of a problem you want to solve, a tool you need, or just something fun to create.\n",
      "    *   A simple to-do list app.\n",
      "    *   A web scraper to collect data.\n",
      "    *   A script to organize files on your computer.\n",
      "    *   A small game.\n",
      "    *   A data visualization project.\n",
      "\n",
      "3.  **Explore Advanced Topics:**\n",
      "    *   **Object-Oriented Programming (OOP):** Master classes, inheritance, and polymorphism.\n",
      "    *   **Decorators and Generators:** Learn these powerful Python features.\n",
      "    *   **Testing:** Get into unit testing with `unittest` or `pytest`.\n",
      "    *   **Performance Optimization:** Understand how to write more efficient Python code.\n",
      "\n",
      "4.  **Engage with the Community:**\n",
      "    *   Join Python subreddits (r/Python, r/learnpython, r/datascience).\n",
      "    *   Attend local Python meetups or online conferences.\n",
      "    *   Contribute to open-source projects (even small bug fixes or documentation improvements are valuable!).\n",
      "    *   Participate in coding challenges (e.g., LeetCode, HackerRank, CodeWars).\n",
      "\n",
      "5.  **Continue Learning:**\n",
      "    *   Read more advanced Python books.\n",
      "    *   Take specialized online courses (Coursera, Udemy, freeCodeCamp, Real Python).\n",
      "    *   Follow Python blogs and podcasts.\n",
      "\n",
      "Keep that passion alive! Python has so much to offer.\n",
      "\n",
      "üìä Updated profile: {'preferences': {}, 'facts': ['Name: Hi!'], 'interests': ['Python programming']}\n",
      "\n",
      "============================================================\n",
      "ü§ñ Assistant: That's fantastic to hear! Python is truly a versatile and powerful language, and its readability, vast ecosystem of libraries, and incredible community make it a favorite for many.\n",
      "\n",
      "What specific aspects do you enjoy most about it, or what kind of projects do you love working on with Python?\n",
      "\n",
      "If you're looking for ways to deepen your skills or explore new areas, here are some ideas:\n",
      "\n",
      "1.  **Dive Deeper into Specific Areas:**\n",
      "    *   **Web Development:** Explore frameworks like **Django** (full-featured) or **Flask** (micro-framework) to build web applications.\n",
      "    *   **Data Science & Machine Learning:** Get into **NumPy**, **Pandas** for data manipulation, and libraries like **Scikit-learn**, **TensorFlow**, or **PyTorch** for AI.\n",
      "    *   **Automation & Scripting:** Learn how to automate repetitive tasks on your computer or interact with APIs.\n",
      "    *   **Game Development:** Check out **Pygame** to create your own 2D games.\n",
      "    *   **GUI Development:** Explore **Tkinter**, **PyQt**, or **Kivy** for creating desktop applications.\n",
      "\n",
      "2.  **Build Personal Projects:** Nothing solidifies learning like building things. Think of a problem you want to solve, a tool you need, or just something fun to create.\n",
      "    *   A simple to-do list app.\n",
      "    *   A web scraper to collect data.\n",
      "    *   A script to organize files on your computer.\n",
      "    *   A small game.\n",
      "    *   A data visualization project.\n",
      "\n",
      "3.  **Explore Advanced Topics:**\n",
      "    *   **Object-Oriented Programming (OOP):** Master classes, inheritance, and polymorphism.\n",
      "    *   **Decorators and Generators:** Learn these powerful Python features.\n",
      "    *   **Testing:** Get into unit testing with `unittest` or `pytest`.\n",
      "    *   **Performance Optimization:** Understand how to write more efficient Python code.\n",
      "\n",
      "4.  **Engage with the Community:**\n",
      "    *   Join Python subreddits (r/Python, r/learnpython, r/datascience).\n",
      "    *   Attend local Python meetups or online conferences.\n",
      "    *   Contribute to open-source projects (even small bug fixes or documentation improvements are valuable!).\n",
      "    *   Participate in coding challenges (e.g., LeetCode, HackerRank, CodeWars).\n",
      "\n",
      "5.  **Continue Learning:**\n",
      "    *   Read more advanced Python books.\n",
      "    *   Take specialized online courses (Coursera, Udemy, freeCodeCamp, Real Python).\n",
      "    *   Follow Python blogs and podcasts.\n",
      "\n",
      "Keep that passion alive! Python has so much to offer.\n",
      "\n",
      "üìä Updated profile: {'preferences': {}, 'facts': ['Name: Hi!'], 'interests': ['Python programming']}\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "### EXAMPLE 2: Context-Aware Agent with User Profile\n",
    "# This agent remembers user preferences and personalizes responses\n",
    "\n",
    "class ContextAwareAgent:\n",
    "    \"\"\"Agent that maintains user context and preferences\"\"\"\n",
    "    \n",
    "    def __init__(self, model, user_id=\"default_user\"):\n",
    "        self.model = model\n",
    "        self.user_id = user_id\n",
    "        self.conversation_history = []\n",
    "        self.user_profile = {\n",
    "            \"preferences\": {},\n",
    "            \"facts\": [],\n",
    "            \"interests\": []\n",
    "        }\n",
    "    \n",
    "    def perceive(self, user_message: str) -> Dict[str, Any]:\n",
    "        \"\"\"Enhanced perception with user context\"\"\"\n",
    "        return {\n",
    "            \"user_message\": user_message,\n",
    "            \"history\": self.conversation_history[-5:],\n",
    "            \"user_preferences\": self.user_profile[\"preferences\"],\n",
    "            \"known_facts\": self.user_profile[\"facts\"],\n",
    "            \"interests\": self.user_profile[\"interests\"]\n",
    "        }\n",
    "    \n",
    "    def extract_and_learn(self, message: str):\n",
    "        \"\"\"Learn from user messages\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        # Detect preferences\n",
    "        if \"i like\" in message_lower or \"i love\" in message_lower:\n",
    "            # Extract what they like (simplified)\n",
    "            if \"python\" in message_lower:\n",
    "                self.user_profile[\"interests\"].append(\"Python programming\")\n",
    "            if \"ai\" in message_lower or \"agent\" in message_lower:\n",
    "                self.user_profile[\"interests\"].append(\"AI and agents\")\n",
    "        \n",
    "        # Detect facts\n",
    "        if \"my name is\" in message_lower:\n",
    "            name = message.split(\"my name is\")[-1].strip().split()[0]\n",
    "            self.user_profile[\"facts\"].append(f\"Name: {name}\")\n",
    "    \n",
    "    def plan(self, perception: Dict) -> List[str]:\n",
    "        \"\"\"Plan with context awareness\"\"\"\n",
    "        plan = [\"extract_preferences\"]\n",
    "        \n",
    "        # Personalize if we know the user\n",
    "        if perception[\"interests\"]:\n",
    "            plan.append(\"generate_personalized_response\")\n",
    "        else:\n",
    "            plan.append(\"generate_response\")\n",
    "        \n",
    "        plan.append(\"store_in_memory\")\n",
    "        return plan\n",
    "    \n",
    "    def act(self, plan: List[str], perception: Dict) -> str:\n",
    "        \"\"\"Execute context-aware actions\"\"\"\n",
    "        response = None\n",
    "        \n",
    "        for action in plan:\n",
    "            if action == \"extract_preferences\":\n",
    "                self.extract_and_learn(perception[\"user_message\"])\n",
    "            \n",
    "            elif action == \"generate_personalized_response\":\n",
    "                context = self._build_rich_context(perception)\n",
    "                response = self.model.generate_content(context).text\n",
    "            \n",
    "            elif action == \"generate_response\":\n",
    "                # Standard response without personalization\n",
    "                context = f\"User: {perception['user_message']}\\n\\nRespond helpfully:\"\n",
    "                response = self.model.generate_content(context).text\n",
    "            \n",
    "            elif action == \"store_in_memory\":\n",
    "                self.conversation_history.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": perception[\"user_message\"]\n",
    "                })\n",
    "                self.conversation_history.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": response\n",
    "                })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _build_rich_context(self, perception: Dict) -> str:\n",
    "        \"\"\"Build context with user information\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        # Add known facts\n",
    "        if perception[\"known_facts\"]:\n",
    "            context_parts.append(\"What I know about you:\")\n",
    "            context_parts.extend([f\"- {fact}\" for fact in perception[\"known_facts\"]])\n",
    "        \n",
    "        # Add interests\n",
    "        if perception[\"interests\"]:\n",
    "            context_parts.append(\"Your interests:\")\n",
    "            context_parts.extend([f\"- {interest}\" for interest in perception[\"interests\"]])\n",
    "        \n",
    "        # Add recent conversation\n",
    "        if perception[\"history\"]:\n",
    "            context_parts.append(\"\\nRecent conversation:\")\n",
    "            for msg in perception[\"history\"]:\n",
    "                context_parts.append(f\"{msg['role']}: {msg['content']}\")\n",
    "        \n",
    "        # Add current message\n",
    "        context_parts.append(f\"\\nUser: {perception['user_message']}\")\n",
    "        context_parts.append(\"\\nRespond in a personalized, helpful way:\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def process(self, user_message: str) -> str:\n",
    "        \"\"\"Process with context awareness\"\"\"\n",
    "        state = self.perceive(user_message)\n",
    "        plan = self.plan(state)\n",
    "        response = self.act(plan, state)\n",
    "        return response\n",
    "\n",
    "\n",
    "# Test context-aware agent\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXAMPLE 2: Context-Aware Agent\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    context_agent = ContextAwareAgent(model, user_id=\"eric\")\n",
    "    \n",
    "    print(\"\\nüí¨ User: Hi! My name is Eric and I'm learning about AI agents.\")\n",
    "    response1 = context_agent.process(\"Hi! My name is Eric and I'm learning about AI agents.\")\n",
    "    print(f\"ü§ñ Assistant: {response1}\")\n",
    "    \n",
    "    print(f\"\\nüìä Agent learned: {context_agent.user_profile}\")\n",
    "    \n",
    "    print(\"\\nüí¨ User: What topics should I study?\")\n",
    "    response2 = context_agent.process(\"What topics should I study?\")\n",
    "    print(f\"ü§ñ Assistant: {response2}\")\n",
    "    \n",
    "    print(\"\\nüí¨ User: I love Python programming!\")\n",
    "    response3 = context_agent.process(\"I love Python programming!\")\n",
    "    print(f\"ü§ñ Assistant: {response3}\")\n",
    "    \n",
    "    print(f\"\\nüìä Updated profile: {context_agent.user_profile}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Configure GOOGLE_API_KEY first (run Cell 7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE 3: Self-Evaluating Agent with Quality Control\n",
    "# This agent evaluates its own responses and improves them\n",
    "\n",
    "class SelfEvaluatingAgent:\n",
    "    \"\"\"Agent that evaluates and improves its own responses\"\"\"\n",
    "    \n",
    "    def __init__(self, model, quality_threshold=7):\n",
    "        self.model = model\n",
    "        self.quality_threshold = quality_threshold  # Out of 10\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def generate_response(self, user_message: str, context: str = \"\") -> str:\n",
    "        \"\"\"Generate initial response\"\"\"\n",
    "        prompt = f\"{context}\\nUser: {user_message}\\n\\nProvide a helpful response:\"\n",
    "        return self.model.generate_content(prompt).text\n",
    "    \n",
    "    def evaluate_response(self, user_message: str, response: str) -> Dict:\n",
    "        \"\"\"Evaluate response quality\"\"\"\n",
    "        eval_prompt = f\"\"\"Evaluate this response on a scale of 1-10:\n",
    "\n",
    "User question: {user_message}\n",
    "Assistant response: {response}\n",
    "\n",
    "Rate the response based on:\n",
    "- Relevance (does it answer the question?)\n",
    "- Completeness (is it thorough?)\n",
    "- Clarity (is it easy to understand?)\n",
    "- Helpfulness (does it provide value?)\n",
    "\n",
    "Provide your rating as: SCORE: X/10\n",
    "Then explain why briefly.\"\"\"\n",
    "        \n",
    "        eval_result = self.model.generate_content(eval_prompt).text\n",
    "        \n",
    "        # Extract score (simplified parsing)\n",
    "        try:\n",
    "            score_line = [line for line in eval_result.split('\\n') if 'SCORE:' in line][0]\n",
    "            score = int(score_line.split('/')[0].split(':')[-1].strip())\n",
    "        except:\n",
    "            score = 5  # Default if parsing fails\n",
    "        \n",
    "        return {\n",
    "            \"score\": score,\n",
    "            \"passed\": score >= self.quality_threshold,\n",
    "            \"evaluation\": eval_result\n",
    "        }\n",
    "    \n",
    "    def improve_response(self, user_message: str, previous_response: str, evaluation: Dict) -> str:\n",
    "        \"\"\"Improve response based on evaluation\"\"\"\n",
    "        improve_prompt = f\"\"\"The previous response was rated {evaluation['score']}/10.\n",
    "\n",
    "User question: {user_message}\n",
    "Previous response: {previous_response}\n",
    "\n",
    "Evaluation feedback:\n",
    "{evaluation['evaluation']}\n",
    "\n",
    "Generate an improved response that addresses the feedback:\"\"\"\n",
    "        \n",
    "        return self.model.generate_content(improve_prompt).text\n",
    "    \n",
    "    def process(self, user_message: str, max_attempts=2) -> Dict:\n",
    "        \"\"\"Process with self-evaluation\"\"\"\n",
    "        context = self._build_context()\n",
    "        \n",
    "        for attempt in range(max_attempts):\n",
    "            print(f\"\\nüîÑ Attempt {attempt + 1}/{max_attempts}\")\n",
    "            \n",
    "            # Generate response\n",
    "            response = self.generate_response(user_message, context)\n",
    "            print(f\"  üìù Generated response ({len(response)} chars)\")\n",
    "            \n",
    "            # Evaluate\n",
    "            evaluation = self.evaluate_response(user_message, response)\n",
    "            print(f\"  üìä Quality score: {evaluation['score']}/10\")\n",
    "            \n",
    "            if evaluation[\"passed\"]:\n",
    "                print(f\"  ‚úÖ Quality threshold met!\")\n",
    "                self._store_in_memory(user_message, response)\n",
    "                return {\n",
    "                    \"response\": response,\n",
    "                    \"quality_score\": evaluation[\"score\"],\n",
    "                    \"attempts\": attempt + 1,\n",
    "                    \"status\": \"success\"\n",
    "                }\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è  Below threshold ({self.quality_threshold}/10), improving...\")\n",
    "                if attempt < max_attempts - 1:\n",
    "                    response = self.improve_response(user_message, response, evaluation)\n",
    "                else:\n",
    "                    print(f\"  ‚è≠Ô∏è  Max attempts reached, using best available response\")\n",
    "                    self._store_in_memory(user_message, response)\n",
    "                    return {\n",
    "                        \"response\": response,\n",
    "                        \"quality_score\": evaluation[\"score\"],\n",
    "                        \"attempts\": attempt + 1,\n",
    "                        \"status\": \"acceptable\"\n",
    "                    }\n",
    "    \n",
    "    def _build_context(self) -> str:\n",
    "        \"\"\"Build conversation context\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"\"\n",
    "        recent = self.conversation_history[-3:]\n",
    "        return \"Previous conversation:\\n\" + \"\\n\".join([\n",
    "            f\"{msg['role']}: {msg['content']}\" for msg in recent\n",
    "        ])\n",
    "    \n",
    "    def _store_in_memory(self, user_message: str, response: str):\n",
    "        \"\"\"Store conversation in memory\"\"\"\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "\n",
    "# Test self-evaluating agent\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXAMPLE 3: Self-Evaluating Agent\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    eval_agent = SelfEvaluatingAgent(model, quality_threshold=7)\n",
    "    \n",
    "    print(\"\\nüí¨ User: Explain AI agents in simple terms\")\n",
    "    result = eval_agent.process(\"Explain AI agents in simple terms\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚ú® Final Response:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(result[\"response\"])\n",
    "    print(f\"\\nüìà Quality Score: {result['quality_score']}/10\")\n",
    "    print(f\"üîÑ Attempts: {result['attempts']}\")\n",
    "    print(f\"üéØ Status: {result['status']}\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Configure GOOGLE_API_KEY first (run Cell 7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1124e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE 4: LLM vs Agent - Side-by-Side Comparison\n",
    "# See the dramatic difference between a simple LLM call and an agent\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXAMPLE 4: LLM vs AGENT COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    # Scenario: Weather and umbrella questions\n",
    "    \n",
    "    print(\"\\n\" + \"üî¥ Traditional LLM Approach (No Memory)\".center(70))\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # First question\n",
    "    print(\"\\nüí¨ User: What's the weather like today?\")\n",
    "    llm_response1 = model.generate_content(\"What's the weather like today?\").text\n",
    "    print(f\"ü§ñ LLM: {llm_response1}\")\n",
    "    \n",
    "    # Second question (LLM has NO MEMORY of first question!)\n",
    "    print(\"\\nüí¨ User: Should I bring an umbrella?\")\n",
    "    llm_response2 = model.generate_content(\"Should I bring an umbrella?\").text\n",
    "    print(f\"ü§ñ LLM: {llm_response2}\")\n",
    "    \n",
    "    print(\"\\n‚ùå Problem: LLM forgot we just talked about weather!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üü¢ Agent Approach (With Memory & Context)\".center(70))\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Create agent\n",
    "    weather_agent = ContextAwareAgent(model)\n",
    "    \n",
    "    # Same questions\n",
    "    print(\"\\nüí¨ User: What's the weather like today?\")\n",
    "    agent_response1 = weather_agent.process(\"What's the weather like today?\")\n",
    "    print(f\"ü§ñ Agent: {agent_response1}\")\n",
    "    \n",
    "    print(\"\\nüí¨ User: Should I bring an umbrella?\")\n",
    "    agent_response2 = weather_agent.process(\"Should I bring an umbrella?\")\n",
    "    print(f\"ü§ñ Agent: {agent_response2}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Agent remembers the context and provides relevant answer!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìä THE KEY DIFFERENCE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\"\"\n",
    "LLM:\n",
    "  - No memory between calls\n",
    "  - Treats each input independently\n",
    "  - Cannot build on previous context\n",
    "  - Like talking to someone with amnesia\n",
    "    \n",
    "Agent:\n",
    "  ‚úì Maintains conversation history\n",
    "  ‚úì Builds context over time\n",
    "  ‚úì References previous interactions\n",
    "  ‚úì Provides coherent multi-turn experience\n",
    "    \"\"\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Configure GOOGLE_API_KEY first (run Cell 7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e160435",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Hands-On Exercises\n",
    "\n",
    "Now it's your turn! Complete these exercises to solidify your understanding.\n",
    "\n",
    "### Exercise Progression:\n",
    "- **Exercise 1** (Beginner): Build a movie recommendation agent  \n",
    "- **Exercise 2** (Intermediate): Create a study buddy agent with planning\n",
    "- **Exercise 3** (Advanced): Implement a self-correcting agent\n",
    "\n",
    "**üí° Tip**: Try each exercise yourself first, then check the solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d90e9a",
   "metadata": {},
   "source": [
    "### üé¨ Exercise 1: Movie Recommendation Agent (Beginner)\n",
    "\n",
    "**Goal**: Build an agent that remembers user's movie preferences and provides personalized recommendations.\n",
    "\n",
    "**Requirements**:\n",
    "1. Track movies the user mentions liking/disliking\n",
    "2. Remember preferred genres\n",
    "3. Provide recommendations based on preferences\n",
    "4. Explain why recommendations match preferences\n",
    "\n",
    "**Starter Template**:\n",
    "```python\n",
    "class MovieAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.liked_movies = []\n",
    "        self.disliked_movies = []\n",
    "        self.preferred_genres = []\n",
    "    \n",
    "    def learn_preference(self, message):\n",
    "        # TODO: Extract movie preferences from message\n",
    "        pass\n",
    "    \n",
    "    def recommend(self):\n",
    "        # TODO: Generate recommendations based on preferences\n",
    "        pass\n",
    "    \n",
    "    def process(self, user_message):\n",
    "        # TODO: Implement the agent loop\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Test Cases**:\n",
    "```python\n",
    "agent = MovieAgent(model)\n",
    "agent.process(\"I loved Inception and The Matrix!\")\n",
    "agent.process(\"What movie should I watch tonight?\")\n",
    "```\n",
    "\n",
    "**Expected Behavior**:\n",
    "- Agent remembers: Inception, The Matrix (sci-fi/thriller)\n",
    "- Recommends similar movies with explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: YOUR CODE HERE\n",
    "# Try implementing the MovieAgent yourself!\n",
    "\n",
    "# Uncomment and complete:\n",
    "# class MovieAgent:\n",
    "#     def __init__(self, model):\n",
    "#         # Your code here\n",
    "#         pass\n",
    "\n",
    "\n",
    "# Test your agent:\n",
    "# if GOOGLE_API_KEY:\n",
    "#     movie_agent = MovieAgent(model)\n",
    "#     print(movie_agent.process(\"I loved Inception and The Matrix!\"))\n",
    "#     print(movie_agent.process(\"What should I watch tonight?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98218003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 SOLUTION (Run this after trying yourself!)\n",
    "\n",
    "class MovieAgent:\n",
    "    \"\"\"Agent that learns movie preferences and provides recommendations\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.liked_movies = []\n",
    "        self.disliked_movies = []\n",
    "        self.preferred_genres = []\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def learn_preference(self, message):\n",
    "        \"\"\"Extract and store movie preferences\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        # Detect liked movies\n",
    "        if any(word in message_lower for word in [\"loved\", \"love\", \"great\", \"amazing\"]):\n",
    "            # Use LLM to extract movie names\n",
    "            extract_prompt = f\"Extract movie titles from: '{message}'. List them separated by commas, or respond with 'none' if no movies mentioned.\"\n",
    "            result = self.model.generate_content(extract_prompt).text.strip()\n",
    "            \n",
    "            if result.lower() != 'none':\n",
    "                movies = [m.strip() for m in result.split(',')]\n",
    "                self.liked_movies.extend(movies)\n",
    "                print(f\"  üìù Learned: User likes {', '.join(movies)}\")\n",
    "        \n",
    "        # Detect disliked movies\n",
    "        if any(word in message_lower for word in [\"hated\", \"hate\", \"terrible\", \"boring\"]):\n",
    "            extract_prompt = f\"Extract movie titles from: '{message}'. List them separated by commas, or respond with 'none' if no movies mentioned.\"\n",
    "            result = self.model.generate_content(extract_prompt).text.strip()\n",
    "            \n",
    "            if result.lower() != 'none':\n",
    "                movies = [m.strip() for m in result.split(',')]\n",
    "                self.disliked_movies.extend(movies)\n",
    "                print(f\"  üìù Learned: User dislikes {', '.join(movies)}\")\n",
    "    \n",
    "    def recommend(self):\n",
    "        \"\"\"Generate personalized recommendations\"\"\"\n",
    "        if not self.liked_movies:\n",
    "            prompt = \"Suggest 3 popular movies with brief descriptions.\"\n",
    "        else:\n",
    "            liked_list = \", \".join(self.liked_movies[-5:])  # Last 5 liked\n",
    "            prompt = f\"\"\"User has enjoyed these movies: {liked_list}\n",
    "\n",
    "Based on their taste, recommend 3 movies they might like.\n",
    "For each recommendation:\n",
    "1. Movie title\n",
    "2. Why it matches their preferences\n",
    "3. Brief description\n",
    "\n",
    "Format as a numbered list.\"\"\"\n",
    "        \n",
    "        return self.model.generate_content(prompt).text\n",
    "    \n",
    "    def process(self, user_message):\n",
    "        \"\"\"Main agent loop\"\"\"\n",
    "        print(f\"\\nüí¨ User: {user_message}\")\n",
    "        \n",
    "        # Learn from message\n",
    "        self.learn_preference(user_message)\n",
    "        \n",
    "        # Check if asking for recommendation\n",
    "        if any(word in user_message.lower() for word in [\"recommend\", \"suggest\", \"what should\", \"what to watch\"]):\n",
    "            response = self.recommend()\n",
    "        else:\n",
    "            # General response with context\n",
    "            context = \"\"\n",
    "            if self.liked_movies:\n",
    "                context = f\"(User likes: {', '.join(self.liked_movies[-3:])})\"\n",
    "            prompt = f\"{context}\\nUser: {user_message}\\nRespond naturally:\"\n",
    "            response = self.model.generate_content(prompt).text\n",
    "        \n",
    "        # Store in history\n",
    "        self.conversation_history.append({\"user\": user_message, \"assistant\": response})\n",
    "        \n",
    "        print(f\"ü§ñ Agent: {response}\")\n",
    "        return response\n",
    "\n",
    "\n",
    "# Test the solution\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"EXERCISE 1 SOLUTION: Movie Recommendation Agent\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    movie_agent = MovieAgent(model)\n",
    "    \n",
    "    movie_agent.process(\"I loved Inception and The Matrix!\")\n",
    "    print(f\"\\nüìä Agent's memory: Liked = {movie_agent.liked_movies}\")\n",
    "    \n",
    "    movie_agent.process(\"What movie should I watch tonight?\")\n",
    "    \n",
    "    movie_agent.process(\"I also really enjoyed Interstellar.\")\n",
    "    print(f\"\\nüìä Updated memory: Liked = {movie_agent.liked_movies}\")\n",
    "    \n",
    "    movie_agent.process(\"Give me another recommendation!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Configure GOOGLE_API_KEY first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f663b",
   "metadata": {},
   "source": [
    "### üìö Exercise 2: Study Buddy Agent (Intermediate)\n",
    "\n",
    "**Goal**: Create an agent that helps users study by breaking topics into manageable chunks and tracking progress.\n",
    "\n",
    "**Requirements**:\n",
    "1. **Plan** study sessions with breaks\n",
    "2. **Track** completed topics\n",
    "3. **Adapt** based on user's understanding\n",
    "4. **Review** previously covered material\n",
    "\n",
    "**Challenge Points**:\n",
    "- Multi-step planning (not just one response)\n",
    "- State management (what's been covered)\n",
    "- Adaptive difficulty (based on user feedback)\n",
    "\n",
    "**Starter Template**:\n",
    "```python\n",
    "class StudyBuddyAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.current_topic = None\n",
    "        self.completed_topics = []\n",
    "        self.study_plan = []\n",
    "        self.understanding_levels = {}  # topic: level (1-5)\n",
    "    \n",
    "    def create_study_plan(self, topic, duration_minutes):\n",
    "        # TODO: Break topic into subtopics with time allocations\n",
    "        pass\n",
    "    \n",
    "    def teach_topic(self, subtopic):\n",
    "        # TODO: Explain the subtopic at appropriate level\n",
    "        pass\n",
    "    \n",
    "    def assess_understanding(self, user_response):\n",
    "        # TODO: Evaluate how well user understands\n",
    "        pass\n",
    "    \n",
    "    def adapt_difficulty(self, understanding_level):\n",
    "        # TODO: Adjust explanation complexity\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Test Scenario**:\n",
    "```python\n",
    "buddy = StudyBuddyAgent(model)\n",
    "buddy.process(\"Help me learn about AI agents for 30 minutes\")\n",
    "# Should create plan with: intro, core concepts, examples, review\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: YOUR CODE HERE\n",
    "# This is more challenging - take your time!\n",
    "\n",
    "# Hint: Think about the 5 components:\n",
    "# - Perceive: What does the agent need to know?\n",
    "# - Plan: How to break down the study session?\n",
    "# - Act: Execute the teaching plan\n",
    "# - Evaluate: Check user's understanding\n",
    "# - Remember: Track progress and understanding levels\n",
    "\n",
    "# Your implementation:\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9226d",
   "metadata": {},
   "source": [
    "### üîß Exercise 3: Self-Correcting Code Agent (Advanced)\n",
    "\n",
    "**Goal**: Build an agent that writes code, tests it, finds errors, and corrects itself.\n",
    "\n",
    "**Requirements**:\n",
    "1. Generate code based on user request\n",
    "2. Execute code to test it\n",
    "3. Detect errors and analyze them\n",
    "4. Generate corrected code\n",
    "5. Iterate until code works\n",
    "\n",
    "**Advanced Concepts**:\n",
    "- **Self-evaluation**: Agent judges its own output\n",
    "- **Iterative improvement**: Multiple attempts\n",
    "- **Error analysis**: Understanding what went wrong\n",
    "- **Confidence scoring**: Know when to stop iterating\n",
    "\n",
    "**Starter Template**:\n",
    "```python\n",
    "class CodeAgent:\n",
    "    def __init__(self, model, max_iterations=3):\n",
    "        self.model = model\n",
    "        self.max_iterations = max_iterations\n",
    "        self.attempt_history = []\n",
    "    \n",
    "    def generate_code(self, requirement):\n",
    "        # TODO: Generate Python code\n",
    "        pass\n",
    "    \n",
    "    def test_code(self, code):\n",
    "        # TODO: Try to execute code safely\n",
    "        pass\n",
    "    \n",
    "    def analyze_error(self, code, error):\n",
    "        # TODO: Understand what went wrong\n",
    "        pass\n",
    "    \n",
    "    def correct_code(self, code, error, analysis):\n",
    "        # TODO: Generate fixed version\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Challenge**: Create a function that calculates factorial, but intentionally make the first attempt have a bug!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8987d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: YOUR CODE HERE\n",
    "# This is the most advanced exercise!\n",
    "\n",
    "# Hint: You'll need to:\n",
    "# 1. Use exec() carefully to run generated code\n",
    "# 2. Catch exceptions and analyze them\n",
    "# 3. Use LLM to both generate AND fix code\n",
    "# 4. Track iterations to prevent infinite loops\n",
    "\n",
    "# Bonus: Add confidence scoring - stop iterating when confident\n",
    "\n",
    "# Your implementation:\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9606ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üêõ Debugging Agents: Common Problems & Solutions\n",
    "\n",
    "When your agent doesn't work as expected, follow this systematic approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924704bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem 1: Agent Has No Memory\n",
    "\n",
    "# ‚ùå BROKEN CODE\n",
    "class BrokenAgent:\n",
    "    def respond(self, message):\n",
    "        return model.generate_content(message).text\n",
    "\n",
    "# Every call forgets the previous one!\n",
    "agent = BrokenAgent()\n",
    "# agent.respond(\"My name is Eric\")\n",
    "# agent.respond(\"What's my name?\")  # Agent won't know!\n",
    "\n",
    "\n",
    "# ‚úÖ FIXED CODE\n",
    "class FixedAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.history = []\n",
    "    \n",
    "    def respond(self, message):\n",
    "        # Add user message to history\n",
    "        self.history.append(f\"User: {message}\")\n",
    "        \n",
    "        # Build context from history\n",
    "        context = \"\\n\".join(self.history[-5:])  # Last 5 messages\n",
    "        prompt = f\"{context}\\nAssistant:\"\n",
    "        \n",
    "        response = self.model.generate_content(prompt).text\n",
    "        \n",
    "        # Add assistant response to history\n",
    "        self.history.append(f\"Assistant: {response}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Test\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"üîß Fix #1: Adding Memory\")\n",
    "    fixed = FixedAgent(model)\n",
    "    print(f\"User: My name is Eric\")\n",
    "    r1 = fixed.respond(\"My name is Eric\")\n",
    "    print(f\"Agent: {r1}\")\n",
    "    \n",
    "    print(f\"\\nUser: What's my name?\")\n",
    "    r2 = fixed.respond(\"What's my name?\")\n",
    "    print(f\"Agent: {r2}\")\n",
    "    print(\"‚úÖ Agent remembers!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a6370",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem 2: No Error Handling\n",
    "\n",
    "# ‚ùå BROKEN CODE\n",
    "def broken_api_call():\n",
    "    response = model.generate_content(\"Hello\")  # What if API is down?\n",
    "    return response.text  # This will crash!\n",
    "\n",
    "\n",
    "# ‚úÖ FIXED CODE\n",
    "def safe_api_call(prompt, retries=3):\n",
    "    \"\"\"Call API with error handling and retries\"\"\"\n",
    "    import time\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return {\"status\": \"success\", \"text\": response.text}\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Attempt {attempt + 1} failed: {str(e)[:50]}...\")\n",
    "            \n",
    "            if attempt < retries - 1:\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                print(f\"  ‚è≥ Waiting {wait_time}s before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"text\": f\"Failed after {retries} attempts\",\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "\n",
    "# Test\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"üîß Fix #2: Error Handling\")\n",
    "    result = safe_api_call(\"Hello! Test message.\")\n",
    "    if result[\"status\"] == \"success\":\n",
    "        print(f\"‚úÖ Success: {result['text'][:100]}...\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed: {result['error']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5430ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem 3: Memory Growing Without Bounds\n",
    "\n",
    "# ‚ùå BROKEN CODE\n",
    "class MemoryHog:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "    \n",
    "    def add_message(self, msg):\n",
    "        self.history.append(msg)  # Grows forever!\n",
    "\n",
    "# After 1000 messages, this will be huge!\n",
    "\n",
    "\n",
    "# ‚úÖ FIXED CODE\n",
    "class SmartMemory:\n",
    "    def __init__(self, max_messages=50):\n",
    "        self.history = []\n",
    "        self.max_messages = max_messages\n",
    "        self.important_facts = []  # Separate long-term memory\n",
    "    \n",
    "    def add_message(self, msg):\n",
    "        \"\"\"Add message with automatic pruning\"\"\"\n",
    "        self.history.append(msg)\n",
    "        \n",
    "        # Keep only recent messages\n",
    "        if len(self.history) > self.max_messages:\n",
    "            self.history = self.history[-self.max_messages:]\n",
    "    \n",
    "    def remember_fact(self, fact):\n",
    "        \"\"\"Store important facts separately\"\"\"\n",
    "        if fact not in self.important_facts:\n",
    "            self.important_facts.append(fact)\n",
    "    \n",
    "    def get_context(self, last_n=10):\n",
    "        \"\"\"Get relevant context for current interaction\"\"\"\n",
    "        context = []\n",
    "        \n",
    "        # Add important facts\n",
    "        if self.important_facts:\n",
    "            context.append(\"Important facts:\")\n",
    "            context.extend(self.important_facts[:5])\n",
    "        \n",
    "        # Add recent history\n",
    "        context.append(\"\\nRecent conversation:\")\n",
    "        context.extend(self.history[-last_n:])\n",
    "        \n",
    "        return \"\\n\".join(context)\n",
    "\n",
    "# Test\n",
    "print(\"üîß Fix #3: Bounded Memory\")\n",
    "smart = SmartMemory(max_messages=5)\n",
    "\n",
    "for i in range(10):\n",
    "    smart.add_message(f\"Message {i}\")\n",
    "\n",
    "print(f\"Total messages sent: 10\")\n",
    "print(f\"Messages in memory: {len(smart.history)} (capped at 5)\")\n",
    "print(f\"‚úÖ Memory stays bounded!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8570cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Best Practices Checklist\n",
    "\n",
    "Use this checklist to ensure your agent is production-ready.\n",
    "\n",
    "### Architecture\n",
    "- [ ] Separate concerns (perceive/plan/act/evaluate/remember)\n",
    "- [ ] Each component has single responsibility\n",
    "- [ ] Components can be tested independently\n",
    "- [ ] Clear interfaces between components\n",
    "\n",
    "### Memory Management\n",
    "- [ ] Conversation history has maximum size\n",
    "- [ ] Important facts stored separately\n",
    "- [ ] Memory cleaned up between sessions (if appropriate)\n",
    "- [ ] Long-term memory persisted to database (if needed)\n",
    "\n",
    "### Error Handling\n",
    "- [ ] All API calls wrapped in try/except\n",
    "- [ ] Retry logic for transient failures\n",
    "- [ ] Exponential backoff implemented\n",
    "- [ ] Graceful fallbacks for failures\n",
    "- [ ] Errors logged with context\n",
    "\n",
    "### Quality Control\n",
    "- [ ] Agent evaluates its own responses\n",
    "- [ ] Quality threshold defined\n",
    "- [ ] Improvement loop for low-quality outputs\n",
    "- [ ] Confidence scoring implemented\n",
    "\n",
    "### Testing\n",
    "- [ ] Unit tests for each component\n",
    "- [ ] Integration tests for full agent loop\n",
    "- [ ] Edge cases covered (empty input, errors, etc.)\n",
    "- [ ] Performance benchmarks established\n",
    "\n",
    "### Performance\n",
    "- [ ] API calls minimized\n",
    "- [ ] Responses cached when appropriate\n",
    "- [ ] Timeouts configured\n",
    "- [ ] Response latency monitored\n",
    "\n",
    "### Security & Safety\n",
    "- [ ] User input validated\n",
    "- [ ] Sensitive data not logged\n",
    "- [ ] API keys stored securely\n",
    "- [ ] Rate limiting implemented\n",
    "- [ ] Content filtering applied\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Day 1 Completion Status\n",
    "\n",
    "### Learning Objectives\n",
    "- [ ] Understand what makes something an \"agent\"\n",
    "- [ ] Identify the 5 core components\n",
    "- [ ] Implement a basic agent\n",
    "- [ ] Add context awareness\n",
    "- [ ] Debug common issues\n",
    "\n",
    "### Practical Skills\n",
    "- [ ] Built SimpleAgent (Example 1)\n",
    "- [ ] Built ContextAwareAgent (Example 2)\n",
    "- [ ] Built SelfEvaluatingAgent (Example 3)\n",
    "- [ ] Compared LLM vs Agent (Example 4)\n",
    "- [ ] Completed at least 1 exercise\n",
    "\n",
    "### Conceptual Understanding\n",
    "- [ ] Read DAY1_CONCEPTS.md\n",
    "- [ ] Understand agent loop (perceive ‚Üí plan ‚Üí act ‚Üí evaluate)\n",
    "- [ ] Know when to use agents vs LLMs\n",
    "- [ ] Understand memory management\n",
    "- [ ] Can debug common agent issues\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** If you've checked most boxes above, you've successfully completed Day 1!\n",
    "\n",
    "**Next Steps**:\n",
    "1. Review any unchecked items\n",
    "2. Complete remaining exercises (if time)\n",
    "3. Document learnings in notes section above\n",
    "4. Get ready for Day 2: Agent Planning & Reasoning\n",
    "\n",
    "**üìö Additional Study** (Optional):\n",
    "- Read the [ReAct paper](https://arxiv.org/abs/2210.03629)\n",
    "- Explore [LangChain Agents](https://python.langchain.com/docs/modules/agents/)\n",
    "- Review [Gemma documentation](https://ai.google.dev/gemma)\n",
    "- Share insights on Discord (#5dgai-question-forum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b0ff2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day 1 Local Experimentation\n",
    "\n",
    "*Use Gemini API to experiment with agent concepts locally while completing official codelabs on Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3575ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Snippet from Codelab 2\n",
    "# Copy your multi-agent system code from Kaggle\n",
    "\n",
    "# Example: Multi-agent architecture\n",
    "\n",
    "\n",
    "# Notes on architecture:\n",
    "# -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369275a",
   "metadata": {},
   "source": [
    "### üë• Codelab 2: Multi-Agent Systems with ADK\n",
    "\n",
    "**Completed on Kaggle**: [Link to your codelab]\n",
    "\n",
    "**System Architecture:**\n",
    "- Number of agents: \n",
    "- Agent roles: \n",
    "- Communication pattern: \n",
    "\n",
    "**Architectural Patterns Explored:**\n",
    "- [ ] Sequential (Agent A ‚Üí Agent B ‚Üí Agent C)\n",
    "- [ ] Parallel (Multiple agents simultaneously)\n",
    "- [ ] Hierarchical (Manager + Workers)\n",
    "- [ ] Other: _______________\n",
    "\n",
    "**What I Built:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Key Learnings:**\n",
    "- Agent specialization\n",
    "- Task routing and delegation\n",
    "- Result synthesis\n",
    "- \n",
    "\n",
    "**Challenges & Solutions:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70920694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Snippet from Codelab 1\n",
    "# Copy interesting code from your Kaggle codelab here\n",
    "\n",
    "# Example: Agent with Google Search integration\n",
    "\n",
    "\n",
    "# Notes on implementation:\n",
    "# -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd80b4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day 1 Kaggle Codelabs\n",
    "\n",
    "### üíª Codelab 1: First Agent with Gemini and ADK\n",
    "\n",
    "**Completed on Kaggle**: [Link to your codelab]\n",
    "\n",
    "**What I Built:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Key Concepts Learned:**\n",
    "- Agent Development Kit (ADK) basics\n",
    "- Tool integration (Google Search)\n",
    "- Prompt engineering for agents\n",
    "- \n",
    "\n",
    "**Challenges Encountered:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Solutions:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a3999",
   "metadata": {},
   "source": [
    "**3. Interoperability & Security**\n",
    "\n",
    "*How do agents work together securely?*\n",
    "\n",
    "**Identity Management:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Constrained Policies:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Security Patterns:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Multi-Agent Coordination:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e2fe1",
   "metadata": {},
   "source": [
    "**2. Agent Ops Discipline**\n",
    "\n",
    "*How do we ensure reliability, governance, and best practices?*\n",
    "\n",
    "**Reliability Considerations:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Governance Frameworks:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Monitoring & Evaluation:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Best Practices:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d0b1c",
   "metadata": {},
   "source": [
    "### üìñ Whitepaper: \"Introduction to Agents\"\n",
    "\n",
    "**1. Taxonomy of Agent Capabilities**\n",
    "\n",
    "*What are the different types and levels of agent capabilities?*\n",
    "\n",
    "**Agent Types:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Capability Levels:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Real-World Examples:**\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d78e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are AI agents and how do they differ from regular AI models?\n",
      "\n",
      "A: Error: name 'model' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Simple Conversational Agent with Gemini\n",
    "# This demonstrates basic agent concepts locally\n",
    "\n",
    "def simple_gemini_agent(prompt, context=\"\"):\n",
    "    \"\"\"\n",
    "    A simple agent using Gemini API for local experimentation.\n",
    "    \n",
    "    Args:\n",
    "        prompt: User input/question\n",
    "        context: Optional context for the agent\n",
    "    \n",
    "    Returns:\n",
    "        Generated response\n",
    "    \"\"\"\n",
    "    if not GOOGLE_API_KEY:\n",
    "        return \"Please set up Google API key first\"\n",
    "    \n",
    "    if context:\n",
    "        full_prompt = f\"Context: {context}\\n\\nUser: {prompt}\\n\\nProvide a helpful response:\"\n",
    "    else:\n",
    "        full_prompt = prompt\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test the agent\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SIMPLE AGENT TEST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    test_prompt = \"What are AI agents and how do they differ from regular AI models?\"\n",
    "    print(f\"\\nQuestion: {test_prompt}\\n\")\n",
    "    response = simple_gemini_agent(test_prompt)\n",
    "    print(f\"Answer: {response}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up GOOGLE_API_KEY to test the agent\")\n",
    "    print(\"Get one from: https://aistudio.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b88eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Agent with Context Awareness\n",
    "\n",
    "def context_aware_agent(prompt, conversation_history=None):\n",
    "    \"\"\"\n",
    "    An agent that maintains conversation context.\n",
    "    \"\"\"\n",
    "    if not GOOGLE_API_KEY:\n",
    "        return \"Please set up Google API key first\"\n",
    "    \n",
    "    if conversation_history:\n",
    "        context = \"\\n\".join([f\"{role}: {msg}\" for role, msg in conversation_history])\n",
    "        full_prompt = f\"Previous conversation:\\n{context}\\n\\nUser: {prompt}\\n\\nAssistant:\"\n",
    "    else:\n",
    "        full_prompt = prompt\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test context-aware agent\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CONTEXT-AWARE AGENT TEST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Simulate a conversation\n",
    "    history = [\n",
    "        (\"User\", \"My name is Eric and I'm learning about AI agents\"),\n",
    "        (\"Assistant\", \"Nice to meet you, Eric! AI agents are fascinating. What would you like to know?\")\n",
    "    ]\n",
    "    \n",
    "    new_prompt = \"What topics should I focus on first?\"\n",
    "    print(f\"\\nConversation History:\")\n",
    "    for role, msg in history:\n",
    "        print(f\"  {role}: {msg}\")\n",
    "    print(f\"\\nNew Question: {new_prompt}\\n\")\n",
    "    \n",
    "    response = context_aware_agent(new_prompt, history)\n",
    "    print(f\"Answer: {response}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up GOOGLE_API_KEY to test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf39b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day 1 Summary & Reflection\n",
    "\n",
    "### ‚úÖ Completed Today\n",
    "- [ ] Listened to podcast episode\n",
    "- [ ] Read whitepaper on Introduction to Agents\n",
    "- [ ] Completed Codelab 1: First agent with ADK\n",
    "- [ ] Completed Codelab 2: Multi-agent systems\n",
    "- [ ] Experimented with local Gemini agents\n",
    "- [ ] Documented key learnings\n",
    "\n",
    "### üí° Key Takeaways from Day 1\n",
    "\n",
    "**1. Main Insight:**\n",
    "\n",
    "\n",
    "**2. Most Interesting Concept:**\n",
    "\n",
    "\n",
    "**3. Biggest Challenge:**\n",
    "\n",
    "\n",
    "**4. How I Overcame It:**\n",
    "\n",
    "\n",
    "### ü§î Questions for Tomorrow's Livestream\n",
    "\n",
    "**Question 1:**\n",
    "\n",
    "\n",
    "**Question 2:**\n",
    "\n",
    "\n",
    "**Question 3:**\n",
    "\n",
    "\n",
    "### üéØ Ideas for Future Projects\n",
    "\n",
    "**1.**\n",
    "\n",
    "\n",
    "**2.**\n",
    "\n",
    "\n",
    "**3.**\n",
    "\n",
    "\n",
    "### üìÖ Preparation for Day 2\n",
    "- [ ] Review Day 1 notes before livestream\n",
    "- [ ] Prepare questions for Discord\n",
    "- [ ] Ready for 11:00 AM PT livestream tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: Your Own Agent Ideas\n",
    "\n",
    "# Use this cell to experiment with your own agent concepts\n",
    "# Try different prompting strategies, contexts, or behaviors\n",
    "\n",
    "# Your experimentation here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01bfba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 2: Agent Planning and Reasoning\n",
    "\n",
    "**Date**: November 10, 2025\n",
    "\n",
    "## Learning Objectives\n",
    "- Understanding agent planning mechanisms\n",
    "- Implementing reasoning capabilities\n",
    "- Chain-of-thought prompting\n",
    "\n",
    "*(Complete after receiving Day 2 materials)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe991eb",
   "metadata": {},
   "source": [
    "### Day 2 Notes\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2: Planning Agent Template\n",
    "\n",
    "class PlanningAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def plan(self, task):\n",
    "        \"\"\"Break down a task into steps\"\"\"\n",
    "        prompt = f\"Break down this task into steps: {task}\\n\\nSteps:\"\n",
    "        return self.model.generate(prompt, max_length=200)\n",
    "    \n",
    "    def reason(self, question):\n",
    "        \"\"\"Use chain-of-thought reasoning\"\"\"\n",
    "        prompt = f\"Think step by step to answer: {question}\\n\\nReasoning:\"\n",
    "        return self.model.generate(prompt, max_length=250)\n",
    "\n",
    "# Test the planning agent\n",
    "# agent = PlanningAgent(gemma_lm)\n",
    "# result = agent.plan(\"Build a chatbot\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31514efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2: Exercises and Experiments\n",
    "\n",
    "# Add your Day 2 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f09c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 3: Tool Use and Function Calling\n",
    "\n",
    "**Date**: November 11, 2025\n",
    "\n",
    "## Learning Objectives\n",
    "- Enable agents to use external tools\n",
    "- Implement function calling\n",
    "- Create multi-tool agents\n",
    "\n",
    "*(Complete after receiving Day 3 materials)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f168b",
   "metadata": {},
   "source": [
    "### Day 3 Notes\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13999267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 3: Tool-Using Agent Template\n",
    "\n",
    "class ToolAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.tools = {}\n",
    "    \n",
    "    def register_tool(self, name, function, description):\n",
    "        \"\"\"Register a tool that the agent can use\"\"\"\n",
    "        self.tools[name] = {\n",
    "            'function': function,\n",
    "            'description': description\n",
    "        }\n",
    "    \n",
    "    def execute(self, task):\n",
    "        \"\"\"Execute a task using available tools\"\"\"\n",
    "        # Implementation will be completed during Day 3\n",
    "        pass\n",
    "\n",
    "# Example tools\n",
    "def calculator(expression):\n",
    "    \"\"\"Simple calculator tool\"\"\"\n",
    "    try:\n",
    "        return eval(expression)\n",
    "    except:\n",
    "        return \"Error in calculation\"\n",
    "\n",
    "# agent = ToolAgent(gemma_lm)\n",
    "# agent.register_tool(\"calculator\", calculator, \"Performs mathematical calculations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0052567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 3: Exercises and Experiments\n",
    "\n",
    "# Add your Day 3 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f71bd9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 4: Memory and Context Management\n",
    "\n",
    "**Date**: November 12, 2025\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement agent memory systems\n",
    "- Manage conversation context\n",
    "- Build stateful agents\n",
    "\n",
    "*(Complete after receiving Day 4 materials)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0743dc",
   "metadata": {},
   "source": [
    "### Day 4 Notes\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7400a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 4: Agent with Memory Template\n",
    "\n",
    "class MemoryAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.conversation_history = []\n",
    "        self.long_term_memory = {}\n",
    "    \n",
    "    def remember(self, key, value):\n",
    "        \"\"\"Store information in long-term memory\"\"\"\n",
    "        self.long_term_memory[key] = value\n",
    "    \n",
    "    def recall(self, key):\n",
    "        \"\"\"Retrieve information from long-term memory\"\"\"\n",
    "        return self.long_term_memory.get(key)\n",
    "    \n",
    "    def chat(self, message):\n",
    "        \"\"\"Chat with context awareness\"\"\"\n",
    "        self.conversation_history.append(('user', message))\n",
    "        \n",
    "        # Build context from history\n",
    "        context = \"\\n\".join([f\"{role}: {msg}\" for role, msg in self.conversation_history[-5:]])\n",
    "        prompt = f\"{context}\\nassistant:\"\n",
    "        \n",
    "        response = self.model.generate(prompt, max_length=150)\n",
    "        self.conversation_history.append(('assistant', response))\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Test memory agent\n",
    "# mem_agent = MemoryAgent(gemma_lm)\n",
    "# mem_agent.remember(\"user_name\", \"Eric\")\n",
    "# response = mem_agent.chat(\"Hello!\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 4: Exercises and Experiments\n",
    "\n",
    "# Add your Day 4 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee9ed1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 5: Capstone Project\n",
    "\n",
    "**Date**: November 13, 2025\n",
    "\n",
    "## Project Requirements\n",
    "- Apply all concepts learned throughout the week\n",
    "- Build a complete AI agent application\n",
    "- Demonstrate agent capabilities\n",
    "\n",
    "*(Complete after receiving Day 5 materials)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a18a2ac",
   "metadata": {},
   "source": [
    "### Capstone Project Notes\n",
    "\n",
    "**Project Idea**:\n",
    "\n",
    "*Describe your capstone project here*\n",
    "\n",
    "**Requirements**:\n",
    "- [ ] Requirement 1\n",
    "- [ ] Requirement 2\n",
    "- [ ] Requirement 3\n",
    "\n",
    "**Architecture**:\n",
    "\n",
    "*Describe your agent architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Project: Main Implementation\n",
    "\n",
    "# Your capstone project code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Project: Testing and Demonstration\n",
    "\n",
    "# Test your agent here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38ad67",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Course Reflection\n",
    "\n",
    "### What I Learned\n",
    "\n",
    "*Add your reflections after completing the course*\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "*What will you build next?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02434e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Gemma Documentation](https://ai.google.dev/gemma)\n",
    "- [Keras Hub Guide](https://keras.io/keras_hub/)\n",
    "- [Course Materials on Kaggle](https://www.kaggle.com)\n",
    "- [Discord Community](https://discord.gg/kaggle)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
