{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48178dc0",
   "metadata": {},
   "source": [
    "# AI Agents Development with Gemma\n",
    "\n",
    "This notebook is designed for the 5-Day AI Agents Intensive Course. It will be updated daily as we progress through the course.\n",
    "\n",
    "**Course Dates**: November 9-13, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367e5fe",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "**Important Note:** For the AI Agents course, the **primary platform is Kaggle Notebooks** where all dependencies are pre-configured. This local setup is optional for experimentation.\n",
    "\n",
    "### Platform Options:\n",
    "1. **Kaggle Notebooks** (Recommended) - All dependencies pre-installed\n",
    "2. **Google Colab** - Good for experimentation\n",
    "3. **Local Setup** - Requires Python 3.11 or earlier for tensorflow-text compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb3925a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Python 3.13.7\n",
      "\n",
      "‚ö†Ô∏è Note: tensorflow-text may not be available for Python 3.13 yet.\n",
      "   Options:\n",
      "   1. Use Kaggle notebooks (recommended for this course)\n",
      "   2. Create a Python 3.11 environment locally\n",
      "   3. Use Google Colab for local experimentation\n"
     ]
    }
   ],
   "source": [
    "# Check Python version for compatibility\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "\n",
    "# tensorflow-text compatibility note\n",
    "if sys.version_info >= (3, 13):\n",
    "    print(\"\\n‚ö†Ô∏è Note: tensorflow-text may not be available for Python 3.13 yet.\")\n",
    "    print(\"   Options:\")\n",
    "    print(\"   1. Use Kaggle notebooks (recommended for this course)\")\n",
    "    print(\"   2. Create a Python 3.11 environment locally\")\n",
    "    print(\"   3. Use Google Colab for local experimentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd63ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (for local experimentation only)\n",
    "# Note: The course codelabs should be completed on Kaggle platform\n",
    "# tensorflow-text requires Python <=3.12 currently\n",
    "\n",
    "%pip install -q -U google-generativeai python-dotenv\n",
    "\n",
    "# Uncomment below if using Python 3.11 or earlier:\n",
    "# %pip install -q -U tensorflow tensorflow-text keras-hub keras jax[cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01dacb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete - 2025-11-09 19:49:00\n",
      "Keras backend: jax\n"
     ]
    }
   ],
   "source": [
    "# Basic imports for notebook\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    print(f\"‚úì Setup complete - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"‚úì google-generativeai loaded\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Run the installation cell above first\")\n",
    "\n",
    "# Optional: These are only needed if using Python 3.11 or earlier with local Gemma\n",
    "try:\n",
    "    import numpy as np\n",
    "    os.environ['KERAS_BACKEND'] = 'jax'\n",
    "    import keras\n",
    "    import keras_hub\n",
    "    print(f\"‚úì Keras backend: {keras.backend.backend()}\")\n",
    "    print(\"  (Optional - only needed for local Gemma experimentation)\")\n",
    "except ImportError:\n",
    "    print(\"‚ÑπÔ∏è  Keras/KerasHub not installed (not required for this course)\")\n",
    "    print(\"   Complete all codelabs on Kaggle where dependencies are pre-configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46166c",
   "metadata": {},
   "source": [
    "## API Configuration\n",
    "\n",
    "Configure Google AI Studio API for additional model access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea6bfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using local .env file\n",
      "‚úì Google AI API configured\n"
     ]
    }
   ],
   "source": [
    "# For Kaggle: Use Kaggle Secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    print(\"‚úì Using Kaggle Secrets\")\n",
    "except:\n",
    "    # For local: Use environment variables\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    print(\"‚úì Using local .env file\")\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    print(\"‚úì Google AI API configured\")\n",
    "else:\n",
    "    print(\"‚ö† Warning: API key not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f1360",
   "metadata": {},
   "source": [
    "## Gemma Model Setup\n",
    "\n",
    "**‚ö†Ô∏è Local Limitation:** Gemma via KerasHub requires `tensorflow-text`, which is not available for Python 3.13+ on Windows.\n",
    "\n",
    "### ‚úÖ Recommended Approach:\n",
    "- **Complete all course codelabs on [Kaggle](https://www.kaggle.com)** where Gemma works perfectly\n",
    "- **Use this notebook** for notes, documentation, and Gemini API experiments\n",
    "\n",
    "### üí° Alternative: Gemini API\n",
    "Below we'll use the Gemini API (which you have configured) to experiment with agent concepts locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4739b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Gemini 2.5 Flash model initialized\n",
      "  Use this for local experimentation\n",
      "  Complete course codelabs on Kaggle!\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Use Gemini API for Local Experimentation\n",
    "# (Complete actual codelabs on Kaggle where Gemma is fully supported)\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    # Initialize Gemini model (using latest stable model)\n",
    "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    print(\"‚úì Gemini 2.5 Flash model initialized\")\n",
    "    print(\"  Use this for local experimentation\")\n",
    "    print(\"  Complete course codelabs on Kaggle!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up Google API key to use Gemini\")\n",
    "    print(\"  Get one from: https://aistudio.google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c65f26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 1: Unit 1 - Introduction to Agents\n",
    "\n",
    "**Date**: November 9, 2025  \n",
    "**Platform**: Complete codelabs on [Kaggle](https://www.kaggle.com)\n",
    "\n",
    "## üìã Today's Assignments\n",
    "\n",
    "### 1. Learning Materials\n",
    "- [ ] **Podcast**: Listen to summary episode for Unit 1 ([NotebookLM](https://notebooklm.google.com/notebook/05b7bc62-fd9e-4f0e-a83f-cc9a8ab209bf))\n",
    "- [ ] **Whitepaper**: Read \"Introduction to Agents\"\n",
    "  - Taxonomy of agent capabilities\n",
    "  - Agent Ops discipline\n",
    "  - Interoperability and security\n",
    "- [ ] **Optional**: Use NotebookLM for Q&A on whitepaper concepts\n",
    "\n",
    "### 2. Hands-On Codelabs (on Kaggle!)\n",
    "- [ ] **Codelab 1**: Build your first agent using Gemini and ADK\n",
    "  - Integrate Google Search for real-time information\n",
    "- [ ] **Codelab 2**: Build multi-agent systems using ADK\n",
    "  - Create teams of specialized agents\n",
    "  - Explore architectural patterns\n",
    "\n",
    "### 3. Tomorrow's Livestream\n",
    "- **Date**: November 10, 11:00 AM PT\n",
    "- **Hosts**: Kanchana Patlolla & Anant Nawalgaria\n",
    "- **Submit questions** on Discord for Kaggle swag!\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Understand AI agent capabilities and taxonomy\n",
    "- Learn ADK (Agent Development Kit) basics\n",
    "- Build conversational agents with tool integration\n",
    "- Create and coordinate multi-agent systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1be80a",
   "metadata": {},
   "source": [
    "## üìö Day 1 Learning Materials\n",
    "\n",
    "### üéß Podcast Notes: Unit 1 Summary Episode\n",
    "\n",
    "**Duration**: ~50 minutes\n",
    "\n",
    "**Key Topics Covered**:\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "**Important Concepts**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Personal Insights**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Questions Raised**:\n",
    "- \n",
    "- \n",
    "\n",
    "---\n",
    "\n",
    "### üìñ Whitepaper: \"Introduction to Agents\"\n",
    "\n",
    "**Reading Time**: 1-2 hours\n",
    "\n",
    "#### 1. Taxonomy of Agent Capabilities\n",
    "\n",
    "**Agent Types & Classifications**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Capability Levels**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Real-World Applications**:\n",
    "- \n",
    "- \n",
    "\n",
    "#### 2. Agent Ops Discipline\n",
    "\n",
    "**Reliability & Performance**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Governance & Compliance**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Monitoring & Evaluation**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Best Practices**:\n",
    "- \n",
    "- \n",
    "\n",
    "#### 3. Interoperability & Security\n",
    "\n",
    "**Identity & Access Management**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Constrained Policies**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Security Patterns**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Multi-Agent Coordination**:\n",
    "- \n",
    "- \n",
    "\n",
    "---\n",
    "\n",
    "### üíª Kaggle Codelab 1: First Agent with Gemini + ADK\n",
    "\n",
    "**Kaggle Link**: [Paste your codelab URL here]\n",
    "\n",
    "**Objective**: Build your first agent using Gemini and integrate Google Search for real-time information.\n",
    "\n",
    "**What I Built**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Key Concepts Learned**:\n",
    "- Agent Development Kit (ADK) fundamentals\n",
    "- Tool integration patterns (Google Search)\n",
    "- Prompt engineering for agents\n",
    "- \n",
    "\n",
    "**Implementation Notes**:\n",
    "```python\n",
    "# Key code snippets from Kaggle codelab:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Challenges & Solutions**:\n",
    "- Challenge: \n",
    "  Solution: \n",
    "- Challenge: \n",
    "  Solution: \n",
    "\n",
    "---\n",
    "\n",
    "### üë• Kaggle Codelab 2: Multi-Agent Systems with ADK\n",
    "\n",
    "**Kaggle Link**: [Paste your codelab URL here]\n",
    "\n",
    "**Objective**: Build multi-agent systems and explore architectural patterns.\n",
    "\n",
    "**System Architecture**:\n",
    "- Number of agents: \n",
    "- Agent roles: \n",
    "- Communication pattern: \n",
    "\n",
    "**Architectural Patterns Explored**:\n",
    "- [ ] Sequential Pipeline (Agent A ‚Üí Agent B ‚Üí Agent C)\n",
    "- [ ] Parallel Processing (Multiple agents simultaneously)\n",
    "- [ ] Hierarchical (Manager + Worker agents)\n",
    "- [ ] Custom: _______________\n",
    "\n",
    "**What I Built**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Implementation Notes**:\n",
    "```python\n",
    "# Key code snippets from Kaggle codelab:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Key Learnings**:\n",
    "- Agent specialization and division of labor\n",
    "- Task routing and delegation strategies\n",
    "- Result synthesis across multiple agents\n",
    "- \n",
    "\n",
    "**Challenges & Solutions**:\n",
    "- Challenge: \n",
    "  Solution: \n",
    "- Challenge: \n",
    "  Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12d78e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIMPLE AGENT TEST\n",
      "============================================================\n",
      "\n",
      "Question: What are AI agents and how do they differ from regular AI models?\n",
      "\n",
      "Answer: The terms \"AI agent\" and \"regular AI model\" are often used, but it's important to understand that a \"regular AI model\" is often a *component* or the *brain* of an AI agent. The distinction lies primarily in **autonomy, goal-orientation, and interaction with the environment.**\n",
      "\n",
      "---\n",
      "\n",
      "### What are Regular AI Models?\n",
      "\n",
      "A **regular AI model** (also often referred to as a foundational model, a trained model, or just an AI system in a basic sense) is a trained algorithm designed to perform a specific task or a set of related tasks.\n",
      "\n",
      "**Key Characteristics:**\n",
      "\n",
      "1.  **Reactive:** They typically wait for an input (a prompt, an image, data) and produce an output based on their training. They don't initiate actions on their own.\n",
      "2.  **Task-Specific (or Broad, but still reactive):**\n",
      "    *   **Narrow AI models:** Trained for a very specific task (e.g., an image classifier identifies cats, a spam filter detects spam).\n",
      "    *   **Large Language Models (LLMs) like GPT-4:** While incredibly versatile, they are still fundamentally reactive. You give it a prompt, it generates text. You give it code, it explains it. It doesn't decide to browse the web or send an email on its own initiative.\n",
      "3.  **Stateless (often):** While they can maintain context within a single interaction (like a long conversation with ChatGPT), they generally don't have long-term memory or recall past interactions outside of their current context window without explicit management.\n",
      "4.  **No Environmental Interaction (Directly):** They process data internally based on their training. They don't typically \"browse the internet,\" \"click buttons,\" \"send emails,\" or \"run code\" themselves unless explicitly integrated into a larger system that provides those tools.\n",
      "5.  **No Intrinsic Goals:** Their \"goal\" is to fulfill the prompt or input they receive. They don't set their own objectives or sub-objectives.\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "*   **Image Classification Model:** Takes an image, outputs \"cat\" or \"dog.\"\n",
      "*   **Google Translate:** Takes text in one language, outputs text in another.\n",
      "*   **DALL-E / Midjourney:** Takes a text prompt, generates an image.\n",
      "*   **ChatGPT (the core language model):** Takes a text prompt, generates a coherent text response.\n",
      "\n",
      "---\n",
      "\n",
      "### What are AI Agents?\n",
      "\n",
      "An **AI agent** is an AI system that is designed to perceive its environment, make decisions, and take actions autonomously to achieve a specific goal or set of goals. It's often built *on top of* or *integrates* one or more regular AI models (like an LLM as its \"brain\").\n",
      "\n",
      "**Key Characteristics (The \"Agentic Loop\"):**\n",
      "\n",
      "1.  **Goal-Oriented:** An agent has a clearly defined objective (e.g., \"research the best marketing strategies for a new product,\" \"book a flight,\" \"write and debug a complex piece of software\"). It proactively works towards this goal.\n",
      "2.  **Perception:** It can gather information from its environment. This might involve:\n",
      "    *   Reading web pages\n",
      "    *   Accessing databases\n",
      "    *   Monitoring system logs\n",
      "    *   Receiving sensor data\n",
      "3.  **Planning & Reasoning:** It can break down a complex goal into smaller, manageable sub-tasks. It can reason about the best sequence of actions to achieve its goal.\n",
      "4.  **Action/Execution:** It can perform actions in its environment using various tools:\n",
      "    *   Calling APIs (e.g., for email, calendar, search engines, e-commerce sites)\n",
      "    *   Browsing the internet\n",
      "    *   Running code\n",
      "    *   Interacting with other software systems\n",
      "    *   (In robotics) Moving physical components\n",
      "5.  **Memory & State:** Agents have memory, which can be short-term (for current task context) and long-term (for remembering past experiences, learned facts, or previous interactions). This allows them to build a persistent understanding of their environment and progress.\n",
      "6.  **Autonomy & Self-Correction:** They operate with a degree of independence, making decisions without constant human intervention. They can monitor their own progress, identify errors, and adjust their plans or actions to stay on track.\n",
      "7.  **Tool Use:** They autonomously decide *which* tools to use and *when* to use them to accomplish their tasks.\n",
      "\n",
      "**Analogy:**\n",
      "\n",
      "*   A **regular AI model** is like a highly intelligent calculator or a specialized oracle. You give it a question or a problem, and it gives you an answer. It doesn't decide to get up and find a calculator, or look up information, or write a report based on the answer.\n",
      "*   An **AI agent** is like a diligent human assistant. You give it a high-level goal (\"plan my trip to Japan\"), and it will:\n",
      "    *   **Perceive:** Research flights, hotels, attractions.\n",
      "    *   **Plan:** Break it down into \"find flights,\" \"find hotels,\" \"create itinerary.\"\n",
      "    *   **Act:** Use travel websites, booking APIs, calendar tools.\n",
      "    *   **Reason & Self-correct:** If a flight is too expensive, it will find alternatives.\n",
      "    *   **Remember:** Keep track of your preferences for future trips.\n",
      "    *   **Report:** Present you with a completed plan.\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "*   **AutoGPT / BabyAGI:** Early examples of autonomous agents that can set sub-goals, use tools (like web browsing, code execution), and iterate to achieve a larger objective.\n",
      "*   **LangChain Agents:** Frameworks that enable LLMs to act as agents by giving them access to tools and memory.\n",
      "*   **Autonomous Research Agent:** Given a research topic, it browses the web, synthesizes information, writes reports, and updates itself with new findings.\n",
      "*   **Code Generation & Debugging Agent:** Writes code, runs tests, identifies errors, and then iteratively fixes its own code until it passes.\n",
      "*   **Personal Digital Assistant:** Manages your calendar, emails, and tasks, proactively reminding you of appointments and handling routine communications.\n",
      "\n",
      "---\n",
      "\n",
      "### How They Differ: Summary Table\n",
      "\n",
      "| Feature                 | Regular AI Model                                       | AI Agent                                                      |\n",
      "| :---------------------- | :------------------------------------------------------- | :------------------------------------------------------------ |\n",
      "| **Autonomy**            | Low / Reactive (waits for input)                       | High / Proactive (initiates actions)                          |\n",
      "| **Goal-Orientation**    | None (responds to current prompt)                        | High (has an overarching objective it pursues)                |\n",
      "| **Interaction with Env.** | Indirect (processes data, doesn't act in the world)      | Direct (perceives, plans, and acts in its environment)        |\n",
      "| **Memory**              | Limited (context window for current interaction)         | Extensive (short-term & long-term, stores experiences)        |\n",
      "| **Planning**            | Minimal (follows explicit instructions)                  | Robust (breaks down goals, sequences actions, self-corrects)  |\n",
      "| **Tool Use**            | Can be given tools, but doesn't decide to use them       | Autonomously chooses and uses tools to achieve goals          |\n",
      "| **Complexity**          | Performs specific task(s)                                | Orchestrates multiple tasks, tools, and reasoning processes  |\n",
      "| **Role**                | A processor, a calculator, an oracle                     | An actor, a problem-solver, a digital assistant               |\n",
      "\n",
      "In essence, an AI agent takes a \"regular AI model\" (especially a powerful LLM) and equips it with the ability to *perceive*, *plan*, *act*, and *remember*, turning it from a reactive tool into an autonomous problem-solver.\n",
      "\n",
      "============================================================\n",
      "Answer: The terms \"AI agent\" and \"regular AI model\" are often used, but it's important to understand that a \"regular AI model\" is often a *component* or the *brain* of an AI agent. The distinction lies primarily in **autonomy, goal-orientation, and interaction with the environment.**\n",
      "\n",
      "---\n",
      "\n",
      "### What are Regular AI Models?\n",
      "\n",
      "A **regular AI model** (also often referred to as a foundational model, a trained model, or just an AI system in a basic sense) is a trained algorithm designed to perform a specific task or a set of related tasks.\n",
      "\n",
      "**Key Characteristics:**\n",
      "\n",
      "1.  **Reactive:** They typically wait for an input (a prompt, an image, data) and produce an output based on their training. They don't initiate actions on their own.\n",
      "2.  **Task-Specific (or Broad, but still reactive):**\n",
      "    *   **Narrow AI models:** Trained for a very specific task (e.g., an image classifier identifies cats, a spam filter detects spam).\n",
      "    *   **Large Language Models (LLMs) like GPT-4:** While incredibly versatile, they are still fundamentally reactive. You give it a prompt, it generates text. You give it code, it explains it. It doesn't decide to browse the web or send an email on its own initiative.\n",
      "3.  **Stateless (often):** While they can maintain context within a single interaction (like a long conversation with ChatGPT), they generally don't have long-term memory or recall past interactions outside of their current context window without explicit management.\n",
      "4.  **No Environmental Interaction (Directly):** They process data internally based on their training. They don't typically \"browse the internet,\" \"click buttons,\" \"send emails,\" or \"run code\" themselves unless explicitly integrated into a larger system that provides those tools.\n",
      "5.  **No Intrinsic Goals:** Their \"goal\" is to fulfill the prompt or input they receive. They don't set their own objectives or sub-objectives.\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "*   **Image Classification Model:** Takes an image, outputs \"cat\" or \"dog.\"\n",
      "*   **Google Translate:** Takes text in one language, outputs text in another.\n",
      "*   **DALL-E / Midjourney:** Takes a text prompt, generates an image.\n",
      "*   **ChatGPT (the core language model):** Takes a text prompt, generates a coherent text response.\n",
      "\n",
      "---\n",
      "\n",
      "### What are AI Agents?\n",
      "\n",
      "An **AI agent** is an AI system that is designed to perceive its environment, make decisions, and take actions autonomously to achieve a specific goal or set of goals. It's often built *on top of* or *integrates* one or more regular AI models (like an LLM as its \"brain\").\n",
      "\n",
      "**Key Characteristics (The \"Agentic Loop\"):**\n",
      "\n",
      "1.  **Goal-Oriented:** An agent has a clearly defined objective (e.g., \"research the best marketing strategies for a new product,\" \"book a flight,\" \"write and debug a complex piece of software\"). It proactively works towards this goal.\n",
      "2.  **Perception:** It can gather information from its environment. This might involve:\n",
      "    *   Reading web pages\n",
      "    *   Accessing databases\n",
      "    *   Monitoring system logs\n",
      "    *   Receiving sensor data\n",
      "3.  **Planning & Reasoning:** It can break down a complex goal into smaller, manageable sub-tasks. It can reason about the best sequence of actions to achieve its goal.\n",
      "4.  **Action/Execution:** It can perform actions in its environment using various tools:\n",
      "    *   Calling APIs (e.g., for email, calendar, search engines, e-commerce sites)\n",
      "    *   Browsing the internet\n",
      "    *   Running code\n",
      "    *   Interacting with other software systems\n",
      "    *   (In robotics) Moving physical components\n",
      "5.  **Memory & State:** Agents have memory, which can be short-term (for current task context) and long-term (for remembering past experiences, learned facts, or previous interactions). This allows them to build a persistent understanding of their environment and progress.\n",
      "6.  **Autonomy & Self-Correction:** They operate with a degree of independence, making decisions without constant human intervention. They can monitor their own progress, identify errors, and adjust their plans or actions to stay on track.\n",
      "7.  **Tool Use:** They autonomously decide *which* tools to use and *when* to use them to accomplish their tasks.\n",
      "\n",
      "**Analogy:**\n",
      "\n",
      "*   A **regular AI model** is like a highly intelligent calculator or a specialized oracle. You give it a question or a problem, and it gives you an answer. It doesn't decide to get up and find a calculator, or look up information, or write a report based on the answer.\n",
      "*   An **AI agent** is like a diligent human assistant. You give it a high-level goal (\"plan my trip to Japan\"), and it will:\n",
      "    *   **Perceive:** Research flights, hotels, attractions.\n",
      "    *   **Plan:** Break it down into \"find flights,\" \"find hotels,\" \"create itinerary.\"\n",
      "    *   **Act:** Use travel websites, booking APIs, calendar tools.\n",
      "    *   **Reason & Self-correct:** If a flight is too expensive, it will find alternatives.\n",
      "    *   **Remember:** Keep track of your preferences for future trips.\n",
      "    *   **Report:** Present you with a completed plan.\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "*   **AutoGPT / BabyAGI:** Early examples of autonomous agents that can set sub-goals, use tools (like web browsing, code execution), and iterate to achieve a larger objective.\n",
      "*   **LangChain Agents:** Frameworks that enable LLMs to act as agents by giving them access to tools and memory.\n",
      "*   **Autonomous Research Agent:** Given a research topic, it browses the web, synthesizes information, writes reports, and updates itself with new findings.\n",
      "*   **Code Generation & Debugging Agent:** Writes code, runs tests, identifies errors, and then iteratively fixes its own code until it passes.\n",
      "*   **Personal Digital Assistant:** Manages your calendar, emails, and tasks, proactively reminding you of appointments and handling routine communications.\n",
      "\n",
      "---\n",
      "\n",
      "### How They Differ: Summary Table\n",
      "\n",
      "| Feature                 | Regular AI Model                                       | AI Agent                                                      |\n",
      "| :---------------------- | :------------------------------------------------------- | :------------------------------------------------------------ |\n",
      "| **Autonomy**            | Low / Reactive (waits for input)                       | High / Proactive (initiates actions)                          |\n",
      "| **Goal-Orientation**    | None (responds to current prompt)                        | High (has an overarching objective it pursues)                |\n",
      "| **Interaction with Env.** | Indirect (processes data, doesn't act in the world)      | Direct (perceives, plans, and acts in its environment)        |\n",
      "| **Memory**              | Limited (context window for current interaction)         | Extensive (short-term & long-term, stores experiences)        |\n",
      "| **Planning**            | Minimal (follows explicit instructions)                  | Robust (breaks down goals, sequences actions, self-corrects)  |\n",
      "| **Tool Use**            | Can be given tools, but doesn't decide to use them       | Autonomously chooses and uses tools to achieve goals          |\n",
      "| **Complexity**          | Performs specific task(s)                                | Orchestrates multiple tasks, tools, and reasoning processes  |\n",
      "| **Role**                | A processor, a calculator, an oracle                     | An actor, a problem-solver, a digital assistant               |\n",
      "\n",
      "In essence, an AI agent takes a \"regular AI model\" (especially a powerful LLM) and equips it with the ability to *perceive*, *plan*, *act*, and *remember*, turning it from a reactive tool into an autonomous problem-solver.\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Simple Conversational Agent with Gemini\n",
    "# This demonstrates basic agent concepts locally\n",
    "\n",
    "def simple_gemini_agent(prompt, context=\"\"):\n",
    "    \"\"\"\n",
    "    A simple agent using Gemini API for local experimentation.\n",
    "    \n",
    "    Args:\n",
    "        prompt: User input/question\n",
    "        context: Optional context for the agent\n",
    "    \n",
    "    Returns:\n",
    "        Generated response\n",
    "    \"\"\"\n",
    "    if not GOOGLE_API_KEY:\n",
    "        return \"Please set up Google API key first\"\n",
    "    \n",
    "    # Check if model is initialized\n",
    "    try:\n",
    "        test_model = model\n",
    "    except NameError:\n",
    "        return \"Please run the Gemini initialization cell (Cell 9) first\"\n",
    "    \n",
    "    if context:\n",
    "        full_prompt = f\"Context: {context}\\n\\nUser: {prompt}\\n\\nProvide a helpful response:\"\n",
    "    else:\n",
    "        full_prompt = prompt\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test the agent\n",
    "if GOOGLE_API_KEY:\n",
    "    try:\n",
    "        # Verify model is initialized\n",
    "        test_model = model\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"SIMPLE AGENT TEST\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        test_prompt = \"What are AI agents and how do they differ from regular AI models?\"\n",
    "        print(f\"\\nQuestion: {test_prompt}\\n\")\n",
    "        response = simple_gemini_agent(test_prompt)\n",
    "        print(f\"Answer: {response}\\n\")\n",
    "        print(\"=\" * 60)\n",
    "    except NameError:\n",
    "        print(\"‚ö†Ô∏è Please run Cell 9 first to initialize the Gemini model\")\n",
    "        print(\"   The model needs to be set up before running experiments\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up GOOGLE_API_KEY to test the agent\")\n",
    "    print(\"   1. Get API key from: https://aistudio.google.com\")\n",
    "    print(\"   2. Create .env file with: GOOGLE_API_KEY=your_key\")\n",
    "    print(\"   3. Re-run Cell 6 to configure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25b88eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONTEXT-AWARE AGENT TEST\n",
      "============================================================\n",
      "\n",
      "Conversation History:\n",
      "  User: My name is Eric and I'm learning about AI agents\n",
      "  Assistant: Nice to meet you, Eric! AI agents are fascinating. What would you like to know?\n",
      "\n",
      "New Question: What topics should I focus on first?\n",
      "\n",
      "Answer: That's a great question, Eric! Focusing on foundational topics first will give you a strong understanding before diving into more complex areas. Here's a suggested path for what to focus on initially:\n",
      "\n",
      "1.  **What is an AI Agent? (The Core Definition)**\n",
      "    *   **Definition and Purpose:** Understand what an AI agent fundamentally is ‚Äì an entity that perceives its environment through sensors and acts upon that environment through effectors.\n",
      "    *   **Key Characteristics:** Learn about common properties like autonomy, reactivity, pro-activity, and goal-orientation. This helps differentiate agents from simple programs.\n",
      "    *   **The Perception-Action Loop:** Grasp the fundamental cycle of an agent: Perceive -> Think/Decide -> Act.\n",
      "\n",
      "2.  **Agent Components:**\n",
      "    *   **Sensors:** How an agent \"sees\" or gathers information (e.g., cameras, microphones, data inputs).\n",
      "    *   **Effectors:** How an agent \"acts\" or influences its environment (e.g., robotic arms, displaying text, sending commands).\n",
      "    *   **The Agent Program/Function:** The \"brain\" or logic that maps perceptions to actions.\n",
      "\n",
      "3.  **Environments:**\n",
      "    *   **Understanding the PEAS Description:** A common framework (Performance measure, Environment, Actuators, Sensors) to define and analyze any agent problem.\n",
      "    *   **Types of Environments:** Learn about different classifications and how they influence agent design:\n",
      "        *   **Observable vs. Partially Observable:** Does the agent see everything?\n",
      "        *   **Deterministic vs. Stochastic:** Are actions always predictable?\n",
      "        *   **Episodic vs. Sequential:** Do current actions affect future states?\n",
      "        *   **Static vs. Dynamic:** Does the environment change while the agent is thinking?\n",
      "        *   **Discrete vs. Continuous:** Are states and actions distinct or fluid?\n",
      "        *   **Single-agent vs. Multi-agent:** Is the agent alone or interacting with others?\n",
      "\n",
      "4.  **Basic Agent Types/Architectures (Conceptual):**\n",
      "    *   **Simple Reflex Agents:** The most basic form, acting purely based on current perception (e.g., \"if-then\" rules).\n",
      "    *   **Model-Based Reflex Agents:** Agents that maintain an internal state of the world to handle partial observability.\n",
      "    *   **Goal-Based Agents:** Agents that use their internal state and knowledge of the world to achieve specific goals.\n",
      "    *   **(Optional for first pass) Utility-Based Agents:** Agents that try to optimize their \"happiness\" or performance over time, often building on goal-based agents.\n",
      "\n",
      "By understanding these initial topics, you'll have a strong conceptual framework for how AI agents are designed, how they operate, and the challenges involved in building them for various applications.\n",
      "\n",
      "Where would you like to start first? We can dive into any of these!\n",
      "\n",
      "============================================================\n",
      "Answer: That's a great question, Eric! Focusing on foundational topics first will give you a strong understanding before diving into more complex areas. Here's a suggested path for what to focus on initially:\n",
      "\n",
      "1.  **What is an AI Agent? (The Core Definition)**\n",
      "    *   **Definition and Purpose:** Understand what an AI agent fundamentally is ‚Äì an entity that perceives its environment through sensors and acts upon that environment through effectors.\n",
      "    *   **Key Characteristics:** Learn about common properties like autonomy, reactivity, pro-activity, and goal-orientation. This helps differentiate agents from simple programs.\n",
      "    *   **The Perception-Action Loop:** Grasp the fundamental cycle of an agent: Perceive -> Think/Decide -> Act.\n",
      "\n",
      "2.  **Agent Components:**\n",
      "    *   **Sensors:** How an agent \"sees\" or gathers information (e.g., cameras, microphones, data inputs).\n",
      "    *   **Effectors:** How an agent \"acts\" or influences its environment (e.g., robotic arms, displaying text, sending commands).\n",
      "    *   **The Agent Program/Function:** The \"brain\" or logic that maps perceptions to actions.\n",
      "\n",
      "3.  **Environments:**\n",
      "    *   **Understanding the PEAS Description:** A common framework (Performance measure, Environment, Actuators, Sensors) to define and analyze any agent problem.\n",
      "    *   **Types of Environments:** Learn about different classifications and how they influence agent design:\n",
      "        *   **Observable vs. Partially Observable:** Does the agent see everything?\n",
      "        *   **Deterministic vs. Stochastic:** Are actions always predictable?\n",
      "        *   **Episodic vs. Sequential:** Do current actions affect future states?\n",
      "        *   **Static vs. Dynamic:** Does the environment change while the agent is thinking?\n",
      "        *   **Discrete vs. Continuous:** Are states and actions distinct or fluid?\n",
      "        *   **Single-agent vs. Multi-agent:** Is the agent alone or interacting with others?\n",
      "\n",
      "4.  **Basic Agent Types/Architectures (Conceptual):**\n",
      "    *   **Simple Reflex Agents:** The most basic form, acting purely based on current perception (e.g., \"if-then\" rules).\n",
      "    *   **Model-Based Reflex Agents:** Agents that maintain an internal state of the world to handle partial observability.\n",
      "    *   **Goal-Based Agents:** Agents that use their internal state and knowledge of the world to achieve specific goals.\n",
      "    *   **(Optional for first pass) Utility-Based Agents:** Agents that try to optimize their \"happiness\" or performance over time, often building on goal-based agents.\n",
      "\n",
      "By understanding these initial topics, you'll have a strong conceptual framework for how AI agents are designed, how they operate, and the challenges involved in building them for various applications.\n",
      "\n",
      "Where would you like to start first? We can dive into any of these!\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Agent with Context Awareness\n",
    "\n",
    "def context_aware_agent(prompt, conversation_history=None):\n",
    "    \"\"\"\n",
    "    An agent that maintains conversation context.\n",
    "    \"\"\"\n",
    "    if not GOOGLE_API_KEY:\n",
    "        return \"Please set up Google API key first\"\n",
    "    \n",
    "    # Check if model is initialized\n",
    "    try:\n",
    "        test_model = model\n",
    "    except NameError:\n",
    "        return \"Please run the Gemini initialization cell (Cell 9) first\"\n",
    "    \n",
    "    if conversation_history:\n",
    "        context = \"\\n\".join([f\"{role}: {msg}\" for role, msg in conversation_history])\n",
    "        full_prompt = f\"Previous conversation:\\n{context}\\n\\nUser: {prompt}\\n\\nAssistant:\"\n",
    "    else:\n",
    "        full_prompt = prompt\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test context-aware agent\n",
    "if GOOGLE_API_KEY:\n",
    "    try:\n",
    "        # Verify model is initialized\n",
    "        test_model = model\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"CONTEXT-AWARE AGENT TEST\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Simulate a conversation\n",
    "        history = [\n",
    "            (\"User\", \"My name is Eric and I'm learning about AI agents\"),\n",
    "            (\"Assistant\", \"Nice to meet you, Eric! AI agents are fascinating. What would you like to know?\")\n",
    "        ]\n",
    "        \n",
    "        new_prompt = \"What topics should I focus on first?\"\n",
    "        print(f\"\\nConversation History:\")\n",
    "        for role, msg in history:\n",
    "            print(f\"  {role}: {msg}\")\n",
    "        print(f\"\\nNew Question: {new_prompt}\\n\")\n",
    "        \n",
    "        response = context_aware_agent(new_prompt, history)\n",
    "        print(f\"Answer: {response}\\n\")\n",
    "        print(\"=\" * 60)\n",
    "    except NameError:\n",
    "        print(\"‚ö†Ô∏è Please run Cell 9 first to initialize the Gemini model\")\n",
    "        print(\"   The model needs to be set up before running experiments\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Set up GOOGLE_API_KEY to test\")\n",
    "    print(\"   1. Get API key from: https://aistudio.google.com\")\n",
    "    print(\"   2. Create .env file with: GOOGLE_API_KEY=your_key\")\n",
    "    print(\"   3. Re-run Cell 6 to configure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf39b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Day 1 Summary & Reflection\n",
    "\n",
    "### ‚úÖ Completion Checklist\n",
    "\n",
    "#### Learning Materials\n",
    "- [ ] **Podcast**: Listened to Unit 1 Summary Episode (~50 min)\n",
    "- [ ] **Whitepaper**: Read \"Introduction to Agents\" (1-2 hours)\n",
    "- [ ] **Optional**: Added whitepaper to NotebookLM for Q&A\n",
    "\n",
    "#### Hands-On Practice\n",
    "- [ ] **Codelab 1**: Built first agent with Gemini + ADK (Kaggle)\n",
    "- [ ] **Codelab 2**: Created multi-agent system with ADK (Kaggle)\n",
    "- [ ] **Local Experiments**: Tested agent concepts with Gemini API\n",
    "\n",
    "#### Documentation & Preparation\n",
    "- [ ] Documented key learnings from all materials\n",
    "- [ ] Noted questions for livestream\n",
    "- [ ] Prepared for November 10 livestream (11:00 AM PT)\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Key Insights & Learnings\n",
    "\n",
    "**1. Most Important Insight**:\n",
    "\n",
    "\n",
    "**2. Most Interesting Concept**:\n",
    "\n",
    "\n",
    "**3. Biggest Challenge**:\n",
    "\n",
    "\n",
    "**4. How I Solved It**:\n",
    "\n",
    "\n",
    "**5. Unexpected Discovery**:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ü§î Questions for Livestream (Nov 10, 11:00 AM PT)\n",
    "\n",
    "**Submit on Discord for Kaggle swag!**\n",
    "\n",
    "**Question 1**:\n",
    "\n",
    "\n",
    "**Question 2**:\n",
    "\n",
    "\n",
    "**Question 3**:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Project Ideas Inspired by Day 1\n",
    "\n",
    "**1.**\n",
    "\n",
    "\n",
    "**2.**\n",
    "\n",
    "\n",
    "**3.**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### üìÖ Ready for Day 2\n",
    "\n",
    "- [ ] Reviewed all Day 1 notes\n",
    "- [ ] Questions prepared for Discord\n",
    "- [ ] Calendar reminder set for livestream\n",
    "- [ ] Fresh mindset for Day 2 materials\n",
    "\n",
    "**Day 2 Focus**: Agent Planning and Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Gemini models:\n",
      "  - models/gemini-2.5-pro-preview-03-25\n",
      "  - models/gemini-2.5-flash-preview-05-20\n",
      "  - models/gemini-2.5-flash\n",
      "  - models/gemini-2.5-flash-lite-preview-06-17\n",
      "  - models/gemini-2.5-pro-preview-05-06\n",
      "  - models/gemini-2.5-pro-preview-06-05\n",
      "  - models/gemini-2.5-pro\n",
      "  - models/gemini-2.0-flash-exp\n",
      "  - models/gemini-2.0-flash\n",
      "  - models/gemini-2.0-flash-001\n",
      "  - models/gemini-2.0-flash-exp-image-generation\n",
      "  - models/gemini-2.0-flash-lite-001\n",
      "  - models/gemini-2.0-flash-lite\n",
      "  - models/gemini-2.0-flash-preview-image-generation\n",
      "  - models/gemini-2.0-flash-lite-preview-02-05\n",
      "  - models/gemini-2.0-flash-lite-preview\n",
      "  - models/gemini-2.0-pro-exp\n",
      "  - models/gemini-2.0-pro-exp-02-05\n",
      "  - models/gemini-exp-1206\n",
      "  - models/gemini-2.0-flash-thinking-exp-01-21\n",
      "  - models/gemini-2.0-flash-thinking-exp\n",
      "  - models/gemini-2.0-flash-thinking-exp-1219\n",
      "  - models/gemini-2.5-flash-preview-tts\n",
      "  - models/gemini-2.5-pro-preview-tts\n",
      "  - models/learnlm-2.0-flash-experimental\n",
      "  - models/gemma-3-1b-it\n",
      "  - models/gemma-3-4b-it\n",
      "  - models/gemma-3-12b-it\n",
      "  - models/gemma-3-27b-it\n",
      "  - models/gemma-3n-e4b-it\n",
      "  - models/gemma-3n-e2b-it\n",
      "  - models/gemini-flash-latest\n",
      "  - models/gemini-flash-lite-latest\n",
      "  - models/gemini-pro-latest\n",
      "  - models/gemini-2.5-flash-lite\n",
      "  - models/gemini-2.5-flash-image-preview\n",
      "  - models/gemini-2.5-flash-image\n",
      "  - models/gemini-2.5-flash-preview-09-2025\n",
      "  - models/gemini-2.5-flash-lite-preview-09-2025\n",
      "  - models/gemini-robotics-er-1.5-preview\n",
      "  - models/gemini-2.5-computer-use-preview-10-2025\n"
     ]
    }
   ],
   "source": [
    "# üß™ Experiment 3: Custom Agent Concepts\n",
    "# \n",
    "# Use this space to experiment with your own agent ideas inspired by Day 1 materials.\n",
    "# Try different prompting strategies, add context, test various behaviors.\n",
    "\n",
    "# Example experiments to try:\n",
    "# - Role-based agents (expert advisor, creative writer, code reviewer)\n",
    "# - Agents with specific personality traits\n",
    "# - Agents with domain-specific knowledge\n",
    "# - Multi-turn conversations with state\n",
    "\n",
    "# Your experimentation code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01bfba",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# üìÖ Day 2: Agent Planning and Reasoning\n",
    "\n",
    "**Date**: November 10, 2025  \n",
    "**Livestream**: 11:00 AM PT with Kanchana Patlolla & Anant Nawalgaria\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "*To be updated after receiving Day 2 materials*\n",
    "\n",
    "- Agent planning mechanisms\n",
    "- Reasoning capabilities\n",
    "- Chain-of-thought prompting\n",
    "- (Additional topics TBD)\n",
    "\n",
    "## üìã Day 2 Assignments\n",
    "*To be updated with specific assignments*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe991eb",
   "metadata": {},
   "source": [
    "## üìö Day 2 Learning Materials\n",
    "\n",
    "### Podcast / Video Notes\n",
    "*Complete after watching/listening to Day 2 content*\n",
    "\n",
    "**Key Topics**:\n",
    "- \n",
    "- \n",
    "\n",
    "**Important Concepts**:\n",
    "- \n",
    "- \n",
    "\n",
    "---\n",
    "\n",
    "### Kaggle Codelabs\n",
    "\n",
    "#### Codelab 1: [Title TBD]\n",
    "*Complete on Kaggle platform*\n",
    "\n",
    "**Kaggle Link**: \n",
    "\n",
    "**What I Built**:\n",
    "- \n",
    "\n",
    "**Key Learnings**:\n",
    "- \n",
    "\n",
    "---\n",
    "\n",
    "#### Codelab 2: [Title TBD]\n",
    "*Complete on Kaggle platform*\n",
    "\n",
    "**Kaggle Link**: \n",
    "\n",
    "**What I Built**:\n",
    "- \n",
    "\n",
    "**Key Learnings**:\n",
    "- \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Day 2 Local Experiments\n",
    "\n",
    "# Experiment code inspired by Day 2 materials\n",
    "# Complete after working through Kaggle codelabs\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f09c6",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# üìÖ Day 3: [Topic TBD]\n",
    "\n",
    "**Date**: November 11, 2025\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "*To be updated after receiving Day 3 materials*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f168b",
   "metadata": {},
   "source": [
    "## üìö Day 3 Learning Materials\n",
    "\n",
    "*Complete after receiving Day 3 content*\n",
    "\n",
    "### Key Concepts\n",
    "- \n",
    "- \n",
    "\n",
    "### Kaggle Codelabs\n",
    "- **Codelab 1**: \n",
    "- **Codelab 2**: \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13999267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Day 3 Local Experiments\n",
    "\n",
    "# Your Day 3 experimentation code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0052567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Day 3 Summary & Reflection\n",
    "\n",
    "# Track your Day 3 progress here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f71bd9",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# üìÖ Day 4: [Topic TBD]\n",
    "\n",
    "**Date**: November 12, 2025\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "*To be updated after receiving Day 4 materials*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0743dc",
   "metadata": {},
   "source": [
    "## üìö Day 4 Learning Materials\n",
    "\n",
    "*Complete after receiving Day 4 content*\n",
    "\n",
    "### Key Concepts\n",
    "- \n",
    "- \n",
    "\n",
    "### Kaggle Codelabs\n",
    "- **Codelab 1**: \n",
    "- **Codelab 2**: \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7400a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Day 4 Local Experiments\n",
    "\n",
    "# Your Day 4 experimentation code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Day 4 Summary & Reflection\n",
    "\n",
    "# Track your Day 4 progress here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee9ed1",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# üìÖ Day 5: Capstone Project\n",
    "\n",
    "**Date**: November 13, 2025\n",
    "\n",
    "## üéØ Project Overview\n",
    "*To be updated after receiving Day 5 materials*\n",
    "\n",
    "### Project Goals\n",
    "- Apply all concepts from Days 1-4\n",
    "- Build a complete AI agent application\n",
    "- Demonstrate comprehensive agent capabilities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a18a2ac",
   "metadata": {},
   "source": [
    "## üìã Capstone Project Planning\n",
    "\n",
    "### Project Concept\n",
    "\n",
    "**Title**: \n",
    "\n",
    "**Description**: \n",
    "\n",
    "**Target Use Case**: \n",
    "\n",
    "---\n",
    "\n",
    "### Requirements Checklist\n",
    "- [ ] Incorporates concepts from Day 1 (Introduction to Agents)\n",
    "- [ ] Applies learning from Day 2 (Planning & Reasoning)\n",
    "- [ ] Utilizes techniques from Day 3 (TBD)\n",
    "- [ ] Implements features from Day 4 (TBD)\n",
    "- [ ] Demonstrates agent capabilities end-to-end\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture Design\n",
    "\n",
    "**Agent Components**:\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "**Data Flow**:\n",
    "\n",
    "\n",
    "**Tools/Integrations**:\n",
    "- \n",
    "- \n",
    "\n",
    "---\n",
    "\n",
    "### Implementation Plan\n",
    "\n",
    "**Phase 1**: \n",
    "- [ ] \n",
    "- [ ] \n",
    "\n",
    "**Phase 2**: \n",
    "- [ ] \n",
    "- [ ] \n",
    "\n",
    "**Phase 3**: \n",
    "- [ ] \n",
    "- [ ] \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Capstone Project: Implementation\n",
    "\n",
    "# Main project code here\n",
    "# Build your complete AI agent application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Capstone Project: Testing & Demonstration\n",
    "\n",
    "# Test cases and demonstration code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38ad67",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## üéì Course Completion & Reflection\n",
    "\n",
    "### üìä Course Summary\n",
    "\n",
    "**Completion Date**: \n",
    "\n",
    "**Total Time Invested**: \n",
    "\n",
    "**Projects Completed**: \n",
    "1. Day 1: Introduction to Agents\n",
    "2. Day 2: \n",
    "3. Day 3: \n",
    "4. Day 4: \n",
    "5. Day 5: Capstone Project\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Key Learnings\n",
    "\n",
    "**Most Valuable Concept**: \n",
    "\n",
    "\n",
    "**Most Challenging Topic**: \n",
    "\n",
    "\n",
    "**Most Useful Tool/Technique**: \n",
    "\n",
    "\n",
    "**Biggest Breakthrough**: \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### üèÜ Major Takeaways\n",
    "\n",
    "1. **Technical Skill**: \n",
    "\n",
    "\n",
    "2. **Conceptual Understanding**: \n",
    "\n",
    "\n",
    "3. **Practical Application**: \n",
    "\n",
    "\n",
    "4. **Best Practices**: \n",
    "\n",
    "\n",
    "5. **Future Potential**: \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Next Steps & Future Projects\n",
    "\n",
    "**Immediate Next Steps** (Next 30 days):\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "**Project Ideas to Build**:\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "**Additional Learning Goals**:\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "---\n",
    "\n",
    "### üìù Personal Notes\n",
    "\n",
    "*Any additional reflections, insights, or ideas*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02434e1",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "### Course Materials\n",
    "- **Kaggle Course Page**: [kaggle.com](https://www.kaggle.com)\n",
    "- **Discord Community**: [Join for discussions and support](https://discord.gg/kaggle)\n",
    "- **Livestream Recordings**: [YouTube playlist link TBD]\n",
    "- **NotebookLM**: [Course Companion Notebook](https://notebooklm.google.com/notebook/05b7bc62-fd9e-4f0e-a83f-cc9a8ab209bf) - AI-generated podcast discussions\n",
    "\n",
    "### Documentation & Guides\n",
    "- **Gemini API**: [ai.google.dev](https://ai.google.dev/)\n",
    "- **Gemma Models**: [ai.google.dev/gemma](https://ai.google.dev/gemma)\n",
    "- **Keras & KerasHub**: [keras.io](https://keras.io)\n",
    "- **Agent Development Kit (ADK)**: [Documentation link TBD]\n",
    "\n",
    "### Learning Resources\n",
    "- **Google AI Studio**: [aistudio.google.com](https://aistudio.google.com)\n",
    "- **Model Garden**: Explore available models\n",
    "- **Code Examples**: Community notebooks and examples\n",
    "\n",
    "### Tools & Platforms\n",
    "- **Kaggle Notebooks**: Pre-configured environment for codelabs\n",
    "- **Google Colab**: Alternative cloud environment\n",
    "- **VS Code**: Local development (this notebook)\n",
    "\n",
    "---\n",
    "\n",
    "*Last updated: November 9, 2025*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
