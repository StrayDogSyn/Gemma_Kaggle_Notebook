{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9ea837",
   "metadata": {},
   "source": [
    "# 5-Day AI Agents Intensive - Setup Notebook\n",
    "\n",
    "This notebook will help you verify your setup and prepare for the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8da66f5",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "\n",
    "Install common packages that may be needed for AI agent development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ab2f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Google AI and related packages\n",
    "%pip install -q google-generativeai google-ai-generativelanguage\n",
    "%pip install -q python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348540d2",
   "metadata": {},
   "source": [
    "## 2. Set Up API Key\n",
    "\n",
    "Store your Google AI Studio API key securely using environment variables or Kaggle Secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef5c2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ API Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (for local development)\n",
    "load_dotenv()\n",
    "\n",
    "# For Kaggle, use Kaggle Secrets instead:\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# For local development with .env file:\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"âœ“ API Key loaded successfully\")\n",
    "else:\n",
    "    print(\"âœ— API Key not found. Please set up your API key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8a0e6",
   "metadata": {},
   "source": [
    "## 3. Test Google Generative AI Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a40071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Connection successful!\n",
      "Response: Hello! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API key\n",
    "if GOOGLE_API_KEY:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    \n",
    "    # Test with a simple prompt\n",
    "    try:\n",
    "        # Use gemini-2.0-flash (current stable model)\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "        response = model.generate_content('Say hello!')\n",
    "        print(\"âœ“ Connection successful!\")\n",
    "        print(f\"Response: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error connecting to API: {e}\")\n",
    "        print(\"\\nTip: Run the next cell to see available models\")\n",
    "else:\n",
    "    print(\"âš  Skipping test - API key not configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e529b84",
   "metadata": {},
   "source": [
    "## 4. List Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab9ac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Gemini models:\n",
      "  - models/gemini-2.5-pro-preview-03-25\n",
      "  - models/gemini-2.5-flash-preview-05-20\n",
      "  - models/gemini-2.5-flash\n",
      "  - models/gemini-2.5-flash-lite-preview-06-17\n",
      "  - models/gemini-2.5-pro-preview-05-06\n",
      "  - models/gemini-2.5-pro-preview-06-05\n",
      "  - models/gemini-2.5-pro\n",
      "  - models/gemini-2.0-flash-exp\n",
      "  - models/gemini-2.0-flash\n",
      "  - models/gemini-2.0-flash-001\n",
      "  - models/gemini-2.0-flash-exp-image-generation\n",
      "  - models/gemini-2.0-flash-lite-001\n",
      "  - models/gemini-2.0-flash-lite\n",
      "  - models/gemini-2.0-flash-preview-image-generation\n",
      "  - models/gemini-2.0-flash-lite-preview-02-05\n",
      "  - models/gemini-2.0-flash-lite-preview\n",
      "  - models/gemini-2.0-pro-exp\n",
      "  - models/gemini-2.0-pro-exp-02-05\n",
      "  - models/gemini-exp-1206\n",
      "  - models/gemini-2.0-flash-thinking-exp-01-21\n",
      "  - models/gemini-2.0-flash-thinking-exp\n",
      "  - models/gemini-2.0-flash-thinking-exp-1219\n",
      "  - models/gemini-2.5-flash-preview-tts\n",
      "  - models/gemini-2.5-pro-preview-tts\n",
      "  - models/learnlm-2.0-flash-experimental\n",
      "  - models/gemma-3-1b-it\n",
      "  - models/gemma-3-4b-it\n",
      "  - models/gemma-3-12b-it\n",
      "  - models/gemma-3-27b-it\n",
      "  - models/gemma-3n-e4b-it\n",
      "  - models/gemma-3n-e2b-it\n",
      "  - models/gemini-flash-latest\n",
      "  - models/gemini-flash-lite-latest\n",
      "  - models/gemini-pro-latest\n",
      "  - models/gemini-2.5-flash-lite\n",
      "  - models/gemini-2.5-flash-image-preview\n",
      "  - models/gemini-2.5-flash-image\n",
      "  - models/gemini-2.5-flash-preview-09-2025\n",
      "  - models/gemini-2.5-flash-lite-preview-09-2025\n",
      "  - models/gemini-robotics-er-1.5-preview\n",
      "  - models/gemini-2.5-computer-use-preview-10-2025\n"
     ]
    }
   ],
   "source": [
    "if GOOGLE_API_KEY:\n",
    "    try:\n",
    "        print(\"Available Gemini models:\")\n",
    "        for model in genai.list_models():\n",
    "            if 'generateContent' in model.supported_generation_methods:\n",
    "                print(f\"  - {model.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing models: {e}\")\n",
    "else:\n",
    "    print(\"âš  Skipping - API key not configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d280f",
   "metadata": {},
   "source": [
    "## 5. Setup Checklist\n",
    "\n",
    "Verify all setup requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d0d662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Checklist:\n",
      "================\n",
      "\n",
      "â—‹ Not on Kaggle (local environment)\n",
      "âœ“ Google API Key configured\n",
      "âœ“ google.generativeai installed\n",
      "âœ“ dotenv installed\n",
      "\n",
      "ðŸ“ Remember to:\n",
      "   1. Phone verify your Kaggle account\n",
      "   2. Join Kaggle Discord: https://discord.gg/kaggle\n",
      "   3. Introduce yourself in #5dgai-introductions\n",
      "   4. Link Kaggle to Discord: https://kaggle.com/discord/confirmation\n"
     ]
    }
   ],
   "source": [
    "print(\"Setup Checklist:\")\n",
    "print(\"================\\n\")\n",
    "\n",
    "# Check Kaggle environment\n",
    "try:\n",
    "    import kaggle\n",
    "    print(\"âœ“ Running on Kaggle\")\n",
    "except ImportError:\n",
    "    print(\"â—‹ Not on Kaggle (local environment)\")\n",
    "\n",
    "# Check API key\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"âœ“ Google API Key configured\")\n",
    "else:\n",
    "    print(\"âœ— Google API Key NOT configured\")\n",
    "\n",
    "# Check required packages\n",
    "packages = ['google.generativeai', 'dotenv']\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "        print(f\"âœ“ {package} installed\")\n",
    "    except ImportError:\n",
    "        print(f\"âœ— {package} NOT installed\")\n",
    "\n",
    "print(\"\\nðŸ“ Remember to:\")\n",
    "print(\"   1. Phone verify your Kaggle account\")\n",
    "print(\"   2. Join Kaggle Discord: https://discord.gg/kaggle\")\n",
    "print(\"   3. Introduce yourself in #5dgai-introductions\")\n",
    "print(\"   4. Link Kaggle to Discord: https://kaggle.com/discord/confirmation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ec62a",
   "metadata": {},
   "source": [
    "## 6. Notes Section\n",
    "\n",
    "Use the cells below to take notes during the course:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd9c90",
   "metadata": {},
   "source": [
    "### Common API Errors & Solutions\n",
    "\n",
    "**Error 429: Rate Limit Exceeded**\n",
    "- **Cause**: Too many requests in a short time\n",
    "- **Solutions**:\n",
    "  1. Use the retry function above (automatic exponential backoff)\n",
    "  2. Add delays between requests: `time.sleep(1)`\n",
    "  3. Reduce request frequency\n",
    "  4. Consider batch processing with delays\n",
    "  \n",
    "**Error 404: Model Not Found**\n",
    "- **Cause**: Using outdated model name (e.g., 'gemini-pro')\n",
    "- **Solution**: Use current model names from cell 8 (e.g., 'gemini-2.0-flash')\n",
    "\n",
    "**Error 400: Invalid Request**\n",
    "- **Cause**: Malformed prompt or invalid parameters\n",
    "- **Solution**: Check prompt format and API parameters\n",
    "\n",
    "**Error 401/403: Authentication Failed**\n",
    "- **Cause**: Invalid or missing API key\n",
    "- **Solution**: Verify API key in `.env` file\n",
    "\n",
    "**Best Practices:**\n",
    "- âœ… Implement retry logic with exponential backoff\n",
    "- âœ… Use global endpoint when possible\n",
    "- âœ… Add appropriate delays between requests\n",
    "- âœ… Monitor your quota usage\n",
    "- âœ… Cache results when appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea0e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing retry logic with a simple prompt:\n",
      "\n",
      "âœ“ Success: Hello from retry logic!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "def generate_with_retry(model, prompt: str, max_retries: int = 3, initial_delay: float = 1.0) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Generate content with automatic retry logic for handling rate limits (429 errors).\n",
    "    \n",
    "    Uses exponential backoff strategy:\n",
    "    - 1st retry: wait 1 second\n",
    "    - 2nd retry: wait 2 seconds\n",
    "    - 3rd retry: wait 4 seconds\n",
    "    \n",
    "    Args:\n",
    "        model: The generative AI model instance\n",
    "        prompt: The text prompt to generate from\n",
    "        max_retries: Maximum number of retry attempts (default: 3)\n",
    "        initial_delay: Initial delay in seconds (default: 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Generated text or None if all retries failed\n",
    "    \"\"\"\n",
    "    delay = initial_delay\n",
    "    \n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            \n",
    "            # Handle rate limit errors (429)\n",
    "            if '429' in error_str or 'quota' in error_str.lower() or 'rate limit' in error_str.lower():\n",
    "                if attempt < max_retries:\n",
    "                    print(f\"âš  Rate limit hit. Retrying in {delay:.1f}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "                    time.sleep(delay)\n",
    "                    delay *= 2  # Exponential backoff\n",
    "                else:\n",
    "                    print(f\"âœ— Rate limit exceeded after {max_retries} retries\")\n",
    "                    print(\"ðŸ’¡ Tip: Wait a few minutes before trying again\")\n",
    "                    return None\n",
    "            \n",
    "            # Handle other errors\n",
    "            else:\n",
    "                print(f\"âœ— Error: {e}\")\n",
    "                return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if GOOGLE_API_KEY:\n",
    "    print(\"Testing retry logic with a simple prompt:\\n\")\n",
    "    \n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "    result = generate_with_retry(model, \"Say 'Hello from retry logic!'\")\n",
    "    \n",
    "    if result:\n",
    "        print(f\"âœ“ Success: {result}\")\n",
    "    else:\n",
    "        print(\"Failed to generate content\")\n",
    "else:\n",
    "    print(\"âš  API key not configured - skipping retry test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d8e48",
   "metadata": {},
   "source": [
    "## 7. API Best Practices & Error Handling\n",
    "\n",
    "Important tips for working with Google AI APIs during the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d754698",
   "metadata": {},
   "source": [
    "### Day 1 Notes (Nov 9, 2025)\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3aeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 1 code experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30426bb9",
   "metadata": {},
   "source": [
    "### Day 2 Notes (Nov 10, 2025)\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2 code experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c98ae",
   "metadata": {},
   "source": [
    "### Day 3 Notes (Nov 11, 2025)\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 3 code experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2632cf8",
   "metadata": {},
   "source": [
    "### Day 4 Notes (Nov 12, 2025)\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 4 code experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21be42",
   "metadata": {},
   "source": [
    "### Day 5 Notes (Nov 13, 2025)\n",
    "\n",
    "*Add your notes here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 5 code experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
